{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347bc0f7-6dbe-454c-a95a-8469d8efe1c2",
   "metadata": {},
   "source": [
    "# SPECFEM Users Workshop -- Day 3 (Oct. 7, 2022)\n",
    "\n",
    "## Part 3b: Seismic Imaging Exercise  \n",
    "\n",
    "- In this notebook we perform a multi-event, multi-station 2D inversion\n",
    "- We will perform all book keeping tasks manually, from running forward simulations to running adjoint simulations  \n",
    "- **Objective**: Heavy-handidly illustrate the laborious book keeping required as inversion problems scale, prompting the need for automated tools    \n",
    "- These instructions should be run from inside a Docker container, using Jupyter Lab (see instructions [here](https://github.com/adjtomo/adjdocs/blob/main/readmes/docker_image_install.md)).  \n",
    "-----------\n",
    "\n",
    "**Relevant Links:** \n",
    "- Today's Notebook: https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/day_3a_imaging_adv.ipynb\n",
    "- Completed Notebook: https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_3a_imaging_adv.ipynb\n",
    "- Day 0 Notebook (Container Testing): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_0_container_testing.ipynb\n",
    "- Day 1A Notebook (Intro SPECFEM): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_1a_intro_specfem2d.ipynb\n",
    "- Day 1B Notebook (Fwd. Simulations): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_1b_forward_simulations.ipynb\n",
    "- Day 2A Notebook (Adj. Simulations): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_2a_kernels.ipynb\n",
    "- Day 3A Notebook (Simple Imaging): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_3a_imaging_simple.ipynb\n",
    "\n",
    "\n",
    "**Jupyter Quick Tips:**\n",
    "\n",
    "- **Run cells** one-by-one by hitting the $\\blacktriangleright$ button at the top, or by hitting `Shift + Enter`\n",
    "- **Run all cells** by hitting the $\\blacktriangleright\\blacktriangleright$ button at the top, or by running `Run -> Run All Cells`\n",
    "- **Currently running cells** that are still processing will have a `[*]` symbol next to them\n",
    "- **Finished cells** will have a `[1]` symbol next to them. The number inside the brackets represents what order this cell has been run in.\n",
    "- Commands that start with `!` are Bash commands (i.e., commands you would run from the terminal)\n",
    "- Commands that start with `%` are Jupyter Magic commands.\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ab8b9f-e443-4f8b-8372-acf7152ee29a",
   "metadata": {},
   "source": [
    "# A Multi-event, Multi-station Inversion\n",
    "\n",
    "- Real seismic inversions use multiple events recorded at multiple stations to increase coverage and reduce nonuniqueness\n",
    "- Here we attempt a *multi-event* ($N=10$), multi-station ($S=10$) model update with the skills we have picked up in previous notebooks\n",
    "- The inversion workflow is as follows: \n",
    "    0) **data**: run $N$ forward simulations to generate *data* using target model ($m_{true}$) for $N$ events and $S$ stations\n",
    "    1) **synthetics**: run $N$ forward simulations to generate synthetics through starting model ($m_{init}$) for $N$ events and $S$ stations\n",
    "    2) **misfit**: quantify data-synthetic misfit ($\\chi_{init}$) and generate adjoint sources for each source-receiver pair ($N\\times S$ waveforms)\n",
    "    3) **kernels**: generate misfit kernels with $N$ adjoint simulation\n",
    "    4) **update**: scale gradient and update initial model to get trial model: $m_{try}$\n",
    "    5) **line search**: run $N$ forward simulations using trial model $m_{try}$ to get $N \\times S$ new synthetic waveforms\n",
    "    6) **line search**: calculate misfit ($\\chi_{try}$) and determine if misfit is reduced ($\\chi_{try} < \\chi_{init}$?)\n",
    "    7) **line search**: if misfit is not reduced ($\\chi_{try} >=  \\chi_{init}$), repeat steps 5-7 with newly scaled gradient\n",
    "    8) **line search**: if misfit is reduced, accept trial model as newly updated model ($m_{try} \\rightarrow m_{01}$)\n",
    "    9) **finalize**: set newly updated model as initial model ($m_{01} \\rightarrow m_{init}$) and repeat steps 1-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cecd59-d906-49b8-a8ce-7aa168c57135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages we might need for today's notebook. You are welcome to import more as you see fit\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from IPython.display import Image\n",
    "from scipy.integrate import simps\n",
    "from seisflows.tools.specfem import Model, read_fortran_binary, write_fortran_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac62cb6f-d1db-43b9-84a3-1a6c63c3bd6e",
   "metadata": {},
   "source": [
    "## 1) Set Up a SPECFEM2D Working Directory\n",
    "\n",
    "- We want to set up a clean working directory to run SPECFEM2D. This will help us preserve our cloned repository and reduce file clutter  \n",
    "- During this example we will use: 10 sources, 10 receivers\n",
    "- *Starting model*: homogeneous halfspace  \n",
    "- *Target model*: perturbation checkerboard  \n",
    "- **Objective**: Generate a misfit kernel and manually update a 2D model, quantify misfit \n",
    "- **NOTE:** We will work in `/home/scoped/work/day_3/inversion_example`. The following cells assume relative paths, so you must evaluate the '%cd' command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fbc100-aba2-4225-8a8d-9445220f2dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we're in an empty working directory\n",
    "! rm -rf /home/scoped/work/day_3/inversion_example\n",
    "! mkdir -p /home/scoped/work/day_3/inversion_example\n",
    "%cd /home/scoped/work/day_3/inversion_example\n",
    "\n",
    "# Setup SPECFEM2D working directory\n",
    "! ln -s /home/scoped/specfem2d/bin .\n",
    "! cp -r /home/scoped/specfem2d/EXAMPLES/Tape2007/DATA .\n",
    "! mkdir OUTPUT_FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e9b7b2-6989-4f8b-9356-ac11ee7712e2",
   "metadata": {},
   "source": [
    "### 1a) Visualize Experimental Setup\n",
    "\n",
    "- We plot the 10 sources and 10 receivers on top of the checkerboard model for context  \n",
    "- The initial model is a homogeneous halfspace, and is **not** plotted here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2057bb78-a098-4bea-a71d-85298c861932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sources_receivers(nevents=25):\n",
    "    \"\"\"\n",
    "    Small code block to plot source-receiver geometry with text labels\n",
    "    Assumes relative pathing\n",
    "    \"\"\"\n",
    "    # Grab Station locations\n",
    "    sta_x, sta_z = np.genfromtxt(\"DATA/STATIONS_checker\", dtype=float, usecols=[2, 3]).T\n",
    "    \n",
    "    # Grab Event locations\n",
    "    ev_x, ev_z = [], []\n",
    "    for i in range(1, nevents+1):\n",
    "        source_file = f\"DATA/SOURCE_{i:0>3}\"\n",
    "        with open(source_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        # Trying to break apart the following line\n",
    "        # 'xs = 299367.72      # source location x in meters\\n'\n",
    "        xs = float(lines[2].split(\"=\")[1].split(\"#\")[0].strip())\n",
    "        zs = float(lines[3].split(\"=\")[1].split(\"#\")[0].strip())\n",
    "\n",
    "        ev_x.append(xs)\n",
    "        ev_z.append(zs)\n",
    "        \n",
    "    # Plot SOURCES and STATIONS geometry\n",
    "    for i, (x, z) in enumerate(zip(sta_x, sta_z)):\n",
    "        plt.scatter(x, z, c=\"c\", marker=\"v\", s=60, edgecolor=\"k\")\n",
    "        # plt.text(x, z, f\"R{i:0>2}\", fontsize=12)\n",
    "    for i, (x, z) in enumerate(zip(ev_x, ev_z)):\n",
    "        plt.scatter(x, z, c=\"y\", marker=\"*\", edgecolor=\"k\", s=150)\n",
    "        plt.text(x, z, f\"S{i+1:0>2}\", fontsize=12, c=\"k\")  # SOURCE numbering starts at 1\n",
    "    \n",
    "    # Finalize plot labels\n",
    "    plt.xlabel(\"X [m]\")\n",
    "    plt.ylabel(\"Z [m]\")\n",
    "    plt.xlim([0, 480E3])\n",
    "    plt.ylim([0, 480E3])\n",
    "    plt.title(\"SOURCE-RECEIVER GEOMETRY\")\n",
    "    \n",
    "    \n",
    "# Load and plot checkerboard model\n",
    "data = np.genfromtxt(\"DATA/model_velocity.dat_checker\", dtype=float, usecols=[1,2,4,5])\n",
    "chkbd_x, chkbd_z, chkbd_vp, chkbd_vs = data.T\n",
    "plt.tricontourf(chkbd_x, chkbd_z, chkbd_vp, levels=125, cmap=\"seismic_r\", alpha=0.1)\n",
    "\n",
    "# Plot sources and receivers on top\n",
    "plot_sources_receivers()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f632f2d-a754-4b1b-88fc-84677e958b98",
   "metadata": {},
   "source": [
    "-----------\n",
    "## 2) Target Model (checkerboard) Synthetics \n",
    "\n",
    "- We'll use the Target checkerboard model used to generate 'data'\n",
    "- Let's first visualize it to help us contexualize the problem  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea0f298-6ccf-473b-b84b-3044f4711bd3",
   "metadata": {},
   "source": [
    "### 2a) Set up the Target Model\n",
    "- We want to set up our forward simulations here  \n",
    "- We'll be using the Checkerboard model to generate 'data'  \n",
    "\n",
    "#### **TASKS TO COMPLETE**:\n",
    "1) Set the correct `DATA/Par_file` for the checkerboard model (*remember* that the checkerboard model parameters are defined in `Par_file_Tape2007_132rec_checker`)\n",
    "2) Tell SPECFEM to save our model in FORTRAN binary format (in the `Par_file`)  \n",
    "3) Tell SPECFEM to save our DATABASE files in FORTRAN binary format (in the `Par_file`)  \n",
    "4) Tell SPECFEM to use our existing STATIONS file, rather than it's own internal definition (in the `Par_file`)  \n",
    "5) Set the number of time steps (NSTEP) to 5000  \n",
    "6) Set the correct naming convention for our checkerboard model, which is currently named `model_velocity.dat_checker` (see Notebook 2A Section 3A)\n",
    "7) Create a STATIONS file with 10 stations (easiest solution is to copy the first ten lines of `STATIONS_checker`)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500a4468-ae34-4630-b65e-d0b982704818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8594956-b4cb-458f-a69e-a0afc5ef5ee7",
   "metadata": {},
   "source": [
    "### 2b) Run the Forward Solver\n",
    "\n",
    "- We want to run 10 simulations to generate 10 sets of target data  \n",
    "- That means we need to run the forward solver **once** per event (i.e., 10 times)\n",
    "- *Remember* that each time we run SPECFEM, it overwrites existing files in the OUTPUT_FILES/ directory\n",
    "\n",
    "#### **TASK TO COMPLETE:**\n",
    "\n",
    "- Run the mesher and solver for **ten** (10) different events  \n",
    "- Use SOURCE_001 -> SOURCE_010 (or any ten sources of your choosing)  \n",
    "- Only use **one** core when running the mesher and solver  \n",
    "- After each solver run, make sure you **store** your synthetic seismograms somewhere they can't be overwritten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec037c1-ac46-41ab-9c0e-6c831c5e017c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58b25d57-4d98-4594-972a-fab2afe47f6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "----------\n",
    "## 3) Initial Model Synthetics\n",
    "\n",
    "- Now let's generate synthetics through a homogeneous halfspace initial model  \n",
    "- **IMPORTANT**: We need to save the forward wavefield (parameter `SAVE_FORWARD`) from the forward simulation of each $N$ events  \n",
    "- *Reminder:* The saved forward wavefield is a snapshot of the forward wavefield at the last time step  \n",
    "\n",
    "### 3a) Set up the Initial Model\n",
    "- We want to set up our forward simulations here  \n",
    "- We'll be using the homogeneous halfspace model to generate synthetics    \n",
    "\n",
    "#### **TASKS TO COMPLETE:**\n",
    "1) Set the correct `Par_file` for the homogeneous halfspace (*remember* homogeneous halfspace is defined by `Par_file_Tape2007_onerec`)\n",
    "2) Tell SPECFEM to save our model in FORTRAN binary format (in the `Par_file`)  \n",
    "3) Tell SPECFEM to save our DATABASE files in FORTRAN binary format (in the `Par_file`)  \n",
    "4) Tell SPECFEM to use our existing STATIONS file, rather than it's own internal definition (in the `Par_file`)  \n",
    "5) Tell SPECFEM to **save** the forward wavefield after our simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b1500-f7b0-471e-b29d-7a780e2a0488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44fd69d5-de19-4164-80a4-f47dd70d765a",
   "metadata": {},
   "source": [
    "### 3b) Run the Forward Solver\n",
    "\n",
    "- We want to run 10 simulations to generate 10 sets of synthetics\n",
    "- That means we need to run the forward solver **once** per event (i.e., 10 times)\n",
    "- *Remember* that each time we run SPECFEM, it overwrites existing files in the OUTPUT_FILES/ directory\n",
    "\n",
    "#### **TASK TO COMPLETE:**\n",
    "\n",
    "- Run the mesher and solver for **ten** (10) different events  \n",
    "- Use the **same** events that you used in Section 2\n",
    "- Only use **one** core when running the mesher and solver  \n",
    "- After each solver run, make sure you **store** your synthetic seismograms somewhere they can't be overwritten\n",
    "- Also make sure to **store** the forward wavefield which has been output by SPECFEM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcfb290-b0b4-4d5f-92f2-1ca0ce6c65e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a63eb49-79af-4df0-9b4f-2e04c712981e",
   "metadata": {},
   "source": [
    "-------------\n",
    "## 4) Quantify Misfit, Generate Adjoint Sources for Initial Model\n",
    "\n",
    "- We want to quantify misfit for all $N \\times S$ waveforms\n",
    "- We also want to generate $N \\times S$ adjoint sources for subsequent adjoint simulations\n",
    "- We'll use a waveform difference misfit for simplicity\n",
    "- Misfit: $ \\chi = \\frac{1}{2} \\int [d(t)-s(t)]^2 dt~$\n",
    "- Adjoint Source: $f^\\dagger (t) = s(t) - d(t)$\n",
    "\n",
    "### 4a) Quantify Misfit and Generate Adjoint Sources\n",
    "\n",
    "#### **TASKS TO COMPLETE:**\n",
    "\n",
    "1) For a given **event** and for each **station** load in 'data' and synthetics  \n",
    "2) Calculate the misfit value: $ \\chi = \\frac{1}{2} \\int [d(t)-s(t)]^2 dt~$, and store its value in a text file (e.g., *'source_001_misfit_initial_model.txt'*)  \n",
    "3) Calculate the adjoint source: $f^\\dagger (t) = s(t) - d(t)$\n",
    "4) Save the adjoint source with the correct format (ASCII) and the correct filename  \n",
    "5) Store adjoint sources per-event (i.e., SOURCE_001 should have it's own directory of adjoint sources)  \n",
    "6) Optional: Plot data and synthetics alongside adjoint sources  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579648e-d5b5-4a75-8e1e-d085731f42f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2990d06-1b94-4524-890f-925745db5688",
   "metadata": {},
   "source": [
    "--------\n",
    "## 5) Run Adjoint Simulations for Event Kernels\n",
    "\n",
    "- Now we need to run the adjoint simulations to generate event kernels\n",
    "- *Remember* that event kernels tell us what parts of the model are sensitive to the misfit function for **EACH** event\n",
    "- **NOTE**: We need to place the adjoint sources in the correct location and also tell SPECFEM that we are running an adjoint simulation\n",
    "- SPECFEM expects adjoint sources in the `SEM/` directory, and formatted exactly the same as its output synthetics\n",
    "\n",
    "#### **TASKS TO COMPLETE:** \n",
    "\n",
    "1) For a given SOURCE that you used to run your forward simulations  \n",
    "2) Make sure that the correct SOURCE is set in the *DATA/* directory  \n",
    "3) Create a '*SEM/*' directory and make sure the correct adjoint sources are linked  \n",
    "4) Make sure the correct forward wavefield (from *save_forward*) is accesible in the 'OUTPUT_FILES/' directory \n",
    "5) Tell SPECFEM that we want to run an adjoint simulation (*simulation_type*)\n",
    "6) Run the adjoint solver with 1 core\n",
    "7) Store the output kernel files (*\\*_kernel.bin*) somewhere safe so they are not overwritten by your next simulation  \n",
    "7) Repeat steps 1-6 for all other SOURCES used for your forward simulations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee116fa-5019-4984-b78f-606a676beb8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af05d6e0-7607-453a-a681-2b78f44633b7",
   "metadata": {},
   "source": [
    "----------\n",
    "## 6) Sum Event Kernels \n",
    "\n",
    "- Now we have $N$=10 event kernels, each representing misfit sensitivity for each of the $N$ events\n",
    "- We need to sum the *event kernels* into a *misfit kernel*, which represents misfit sensitivity for **all** $N$ events\n",
    "- We can use the `xcombine_sem` executable to sum these kernels into the **gradient**\n",
    "\n",
    "#### **TASK TO COMPLETE**:\n",
    "\n",
    "- Combine the `alpha` and `beta` kernels for **all** ten events using the executable `xcombine_sem`\n",
    "- Remember that the command line call of `xcombine_sem` is:\n",
    "\n",
    "```bash\n",
    "mpirun -n NPROC bin/xcombine_sem KERNEL_NAMES INPUT_FILE OUTPUT_DIR\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `KERNEL_NAMES`: the name of the kernels you want to smooth, corresponding to the filenames (e.g., proc000000_alpha_kernel.bin corresponds to 'alpha_kernel')    \n",
    "- `INPUT_FILE`: a text file that lists the full paths to **all** your kernel files. You should have 10 lines per kernel name since we have 10 events  \n",
    "- `OUTPUT_DIR`: a directory where SPECFEM can output the **gradient**    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823aa354-b454-4595-8e9a-a114fbeb19ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b54ad08-0b1d-49d4-95d7-d8924d8c578f",
   "metadata": {},
   "source": [
    "----------\n",
    "## 7) Smoothing/Regularizing Gradient\n",
    "\n",
    "- We want to use regularization to smooth out the gradient to get a more conservative picture of model updates  \n",
    "- We use the `xsmooth_sem` executable to smooth our kernels  \n",
    "- We should choose smoothing length based on the shortest period of our data  \n",
    "- Because we know the target model, we smooth conservatively to the length scale of the checkerboards ($\\Gamma$=50km)  \n",
    "- The SPECFEM smoothing code convolves the kernel with a Gaussian. We are allowed to choose the half-width of the Gaussian  \n",
    "- The relationship between half-width and full-width is $\\Gamma\\approx2.355\\sigma$, so we choose $\\sigma$=20km  \n",
    "\n",
    " The usage of `xsmooth_sem` is given as\n",
    " ```bash\n",
    " USAGE:  mpirun -np NPROC bin/xsmooth_sem SIGMA_H SIGMA_V KERNEL_NAME INPUT_DIR OUPUT_DIR GPU_MODE\n",
    " ```\n",
    " We will need to choose values and directories to make this work\n",
    "  - `SIGMA_H`: Horizontal smoothing length [m] representing the horizontal half-width of the Gaussian  \n",
    "  - `SIGMA_Z`: Vertical smoothing length [m] representing the vertical half-width of the Gaussian  \n",
    "  - `KERNEL_NAME`: The name of the kernel we want to smooth. Must match filename, so `proc000000_vs_kernel.bin` will correspond to kernel name `vs_kernel`  \n",
    "  - `INPUT_DIR`: where SPECFEM can find the kernel files\n",
    "  - `OUTPUT_DIR`: Where SPECFEM should output the SMOOTHED kernels \n",
    "  - `GPU_MODE`: Use GPU acceleration to speed up the smoothing operation (.true. or .false.)\n",
    "  \n",
    "#### **TASKS TO COMPLETE:**\n",
    "\n",
    "1) Make sure all your model files (located in *DATA/\\*.bin*) and gradient files (located where `xcombine_sem` outputted them) are in the same place \n",
    "2) Smooth your `alpha` and `beta` kernels by 20km in the horizontal and vertical directions  \n",
    "3) Remember to keep track of your smoothed and raw gradient. We will proceed with our **smoothed** gradient  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64789f2e-6ba5-4a7d-bda6-b98dfcee227c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eec5ea7a-91fe-4276-ac4f-616a5a783b48",
   "metadata": {},
   "source": [
    "-------------\n",
    "## 8) Scaling the Gradient and Perturbing the Initial Model\n",
    "\n",
    "- We need to **scale** the gradient before using it to perturb the initial model  \n",
    "- We can use SeisFlows utility functions to read in the gradient files  \n",
    "\n",
    "#### **TASKS TO COMPLETE:**\n",
    "- Copy and adjust the PATHS and complete tasks in this code block before running it\n",
    "- **Only** update seismic velocity Vp and Vs  (during your own research, other quantities may be updated)  \n",
    "\n",
    "\n",
    "```python\n",
    "# Copy and edit the code below\n",
    "gradient_vp = read_fortran_binary(PATH_TO_ALPHA_SMOOTH)\n",
    "gradient_vs = read_fortran_binary(PATH_TO_BETA_SMOOTH)\n",
    "\n",
    "model_init_vp = read_fortran_binary(PATH_TO_MODEL_VP)\n",
    "model_init_vs = read_fortran_binary(PATH_TO_MODEL_VS)\n",
    "\n",
    "# TASKS TO COMPLETE HERE\n",
    "# 1) SCALE the gradient so that it is at max 10% of the PEAK Vp or Vs value\n",
    "# 2) SUBTRACT the gradient from its respective model in new parameters: 'model_01_vs', 'model_01_vp'\n",
    "# 3) Match the formatting of the 'write' functions below, which will OVERWRITE our initial model\n",
    "\n",
    "# Overwrites Vp and Vs for Model 01 with perturbed model parameters\n",
    "write_fortran_binary(model_01_vp, \"DATA/proc000000_vp.bin\")\n",
    "write_fortran_binary(model_01_vs, \"DATA/proc000000_vs.bin\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c93df-f987-4c63-897a-39ceee7086b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e07abdc-e9e5-4b51-ab88-6f99c96490e5",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## 9) Run Forward Simulations with Updated Model\n",
    "\n",
    "- Now that we have a perturbed model (Model 01) we can use it to run forward simulations\n",
    "- We'll calculate misfit for each of the new synthetics \n",
    "- We can compare the overall misfit of the initial model to Model 01\n",
    "\n",
    "\n",
    "#### **TASKS TO COMPLETE:**\n",
    "\n",
    "1) Tell SPECFEM that we want to run forward simulations again  \n",
    "2) Tell SPECFEM that we want to use a 'gll' model (`model`=gll)\n",
    "3) Choose one of your 10 events that you used to run your original forward simulations    \n",
    "4) Run mesher and solver\n",
    "5) Quantify misfit for each set of synthetics, save misfit to a text file (e.g., *'source_001_misfit_updated_model.txt'*)  \n",
    "6) Repeat Steps 3-5 for all events  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa3506-55c3-4695-8d8c-f8260cc103d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0747efad-cd1d-496a-aa52-885dc03afe1b",
   "metadata": {},
   "source": [
    "### 9a) Optional: Visualize Waveform Differences\n",
    "\n",
    "#### **TASKS TO COMPLETE**\n",
    "- Plot initial model synthetics against updated model synthetics for one or all synthetics, to check that waveforms have changed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b01e11-ec0f-40cd-a5c7-39c74bc576b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a63f68d1-0c03-4e2d-827a-1f441c8f031c",
   "metadata": {},
   "source": [
    "----------------\n",
    "## 10) Compare Misfit between Initial and Updated models\n",
    "- Now we have two files containing misfit, one for the initial model, and one for the updated model (M01)  \n",
    "- Each line in the misfit file corresponds to the overall misfit for a single event  \n",
    "- We can compare them by taking the average of all lines in the misfit file  \n",
    "\n",
    "\n",
    "#### **TASKS TO COMPLETE:**\n",
    "1) Gather all misfit text files for your initial model\n",
    "2) For one given event, read in the text file and sum all the lines in the file (summing misfit from all stations)  \n",
    "3) Divide this value by the number of stations (or number of lines)  \n",
    "4) Repeat steps 1-3 for all events  \n",
    "5) Sum all values gathered in (4) \n",
    "6) Divide number retrieved in line 5 by the number of events  \n",
    "7) Repeat Steps 1-6 for updated model\n",
    "8) Compare recovered misfit value between initial and updated model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c9486-3d63-48b7-ba05-6270bf253f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
