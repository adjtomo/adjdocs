{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347bc0f7-6dbe-454c-a95a-8469d8efe1c2",
   "metadata": {},
   "source": [
    "# SPECFEM Users Workshop -- Day 3 (Oct. 7, 2022)\n",
    "\n",
    "# TO DO (ctrl+f `!!!`):\n",
    "- Add Day 3 slides (this cell)\n",
    "- Check model update equation (Section 3)\n",
    "- Explain difference between sensitivity kernel, misfit kernel, event kernel, gradient (section 3)\n",
    "\n",
    "\n",
    "\n",
    "## Part 3b: Seismic Imaging (advanced)\n",
    "\n",
    "- In this notebook we perform a multi-event, multi-station 2D inversion\n",
    "- We will perform all book keeping tasks manually\n",
    "- At the end of the notebook, we perform the same inversion using SeisFlows\n",
    "- **Objective**: Illustrate the laborious book keeping required as inversion problems scale\n",
    "- These instructions should be run from inside the Docker container, using Jupyter Lab (see *Docker Preamble* in Day 0). \n",
    "\n",
    "-----------\n",
    "\n",
    "**Relevant Links:** \n",
    "- Day 3 Slides !!! ADD THIS !!!\n",
    "- Today's Notebook: https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/day_3a_imaging_adv.ipynb\n",
    "- Completed Notebook: https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_3a_imaging_adv.ipynb\n",
    "- Day 0 Notebook (Container Testing): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_0_container_testing.ipynb\n",
    "- Day 1A Notebook (Intro SPECFEM): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_1a_intro_specfem2d.ipynb\n",
    "- Day 1B Notebook (Fwd. Simulations): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_1b_forward_simulations.ipynb\n",
    "- Day 2A Notebook (Adj. Simulations): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_2a_kernels.ipynb\n",
    "- Day 3A Notebook (Simple Imaging): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_3a_imaging_simple.ipynb\n",
    "\n",
    "\n",
    "**Jupyter Quick Tips:**\n",
    "\n",
    "- **Run cells** one-by-one by hitting the $\\blacktriangleright$ button at the top, or by hitting `Shift + Enter`\n",
    "- **Run all cells** by hitting the $\\blacktriangleright\\blacktriangleright$ button at the top, or by running `Run -> Run All Cells`\n",
    "- **Currently running cells** that are still processing will have a `[*]` symbol next to them\n",
    "- **Finished cells** will have a `[1]` symbol next to them. The number inside the brackets represents what order this cell has been run in.\n",
    "- Commands that start with `!` are Bash commands (i.e., commands you would run from the terminal)\n",
    "- Commands that start with `%` are Jupyter Magic commands.\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ab8b9f-e443-4f8b-8372-acf7152ee29a",
   "metadata": {},
   "source": [
    "# A Multi-event, Multi-station Inversion\n",
    "\n",
    "- Real seismic inversions use multiple events recorded at multiple stations to increase coverage and reduce nonuniqueness\n",
    "- Here we attempt a *multi-event* ($N=10$), multi-station ($S=10$) model update with the skills we have picked up in previous notebooks\n",
    "- The inversion workflow is as follows: \n",
    "    0) **data**: run $N$ forward simulations to generate *data* using target model ($m_{true}$) for $N$ events and $S$ stations\n",
    "    1) **synthetics**: run $N$ forward simulations to generate synthetics through starting model ($m_{init}$) for $N$ events and $S$ stations\n",
    "    2) **misfit**: quantify data-synthetic misfit ($\\chi_{init}$) and generate adjoint sources for each source-receiver pair ($N\\times S$ waveforms)\n",
    "    3) **kernels**: generate misfit kernels with $N$ adjoint simulation\n",
    "    4) **update**: scale gradient and update initial model to get trial model: $m_{try}$\n",
    "    5) **line search**: run $N$ forward simulations using trial model $m_{try}$ to get $N \\times S$ new synthetic waveforms\n",
    "    6) **line search**: calculate misfit ($\\chi_{try}$) and determine if misfit is reduced ($\\chi_{try} < \\chi_{init}$?)\n",
    "    7) **line search**: if misfit is not reduced ($\\chi_{try} >=  \\chi_{init}$), repeat steps 5-7 with newly scaled gradient\n",
    "    8) **line search**: if misfit is reduced, accept trial model as newly updated model ($m_{try} \\rightarrow m_{01}$)\n",
    "    9) **finalize**: set newly updated model as initial model ($m_{01} \\rightarrow m_{init}$) and repeat steps 1-9\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cecd59-d906-49b8-a8ce-7aa168c57135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from IPython.display import Image\n",
    "from scipy.integrate import simps\n",
    "from seisflows.tools.specfem import Model, read_fortran_binary, write_fortran_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac62cb6f-d1db-43b9-84a3-1a6c63c3bd6e",
   "metadata": {},
   "source": [
    "## 1) Set Up a SPECFEM2D Working Directory\n",
    "\n",
    "- We want to set up a clean working directory to run SPECFEM2D inside. This will help us preserve our cloned repository and reduce file clutter.\n",
    "- 10 sources, 10 receivers\n",
    "- Starting model: homogeneous halfspace\n",
    "- Target model: perturbation checkerboard.\n",
    "- **Objective**: Generate a misfit kernel and manually update a 2D model, quantify misfit \n",
    "- **NOTE:** We will work in `/home/scoped/work/day_3/inversion_example`. The following cells assume relative paths, so you must evaluate the '%cd' command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fbc100-aba2-4225-8a8d-9445220f2dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we're in an empty working directory\n",
    "! rm -rf /home/scoped/work/day_3/inversion_example\n",
    "! mkdir -p /home/scoped/work/day_3/inversion_example\n",
    "%cd /home/scoped/work/day_3/inversion_example\n",
    "\n",
    "# Setup SPECFEM2D working directory\n",
    "! ln -s /home/scoped/specfem2d/bin .\n",
    "! cp -r /home/scoped/specfem2d/EXAMPLES/Tape2007/DATA .\n",
    "! mkdir OUTPUT_FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f632f2d-a754-4b1b-88fc-84677e958b98",
   "metadata": {},
   "source": [
    "## 2) Target Model (checkerboard) Synthetics (n=100)\n",
    "\n",
    "- We use the Target checkerboard model used to generate 'data'\n",
    "- 10 sources and 10 stations with pre-defined locations\n",
    "- Set the Par_file to output Model files in Fortran binary which we will use for visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b28770-0cf8-40c3-af6d-d55049b3db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/scoped/work/day_3/inversion_example\n",
    "\n",
    "# Set up the Par_file\n",
    "! cp -f DATA/Par_file_Tape2007_132rec_checker DATA/Par_file\n",
    "\n",
    "! seisflows sempar -P DATA/Par_file save_model binary\n",
    "! seisflows sempar -P DATA/Par_file setup_with_binary_database 1\n",
    "! seisflows sempar -P DATA/Par_file use_existing_stations .true.\n",
    "! seisflows sempar -P DATA/Par_file NSTEP 5000  # 4800 -> 5000 to match the other Par_file\n",
    "\n",
    "# Ensure that we're using stations 1-10\n",
    "! head -10 DATA/STATIONS_checker > DATA/STATIONS  \n",
    "\n",
    "# Ensure that SPECFEM can find the checkerboard model by naming it correctly\n",
    "! cp -f DATA/model_velocity.dat_checker DATA/proc000000_model_velocity.dat_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e9b7b2-6989-4f8b-9356-ac11ee7712e2",
   "metadata": {},
   "source": [
    "### a) Visualize Experimental Setup\n",
    "\n",
    "- We plot the 10 sources and 10 receivers with text labels\n",
    "- Also plot the underlying checkerboard model to see where the perturbatiosn are\n",
    "- The initial model is a homogeneous halfspace and is **not** plotted here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2057bb78-a098-4bea-a71d-85298c861932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sources_receivers(nevents=10):\n",
    "    \"\"\"\n",
    "    Small code block to plot source-receiver geometry with text labels\n",
    "    Assumes relative pathing\n",
    "    \"\"\"\n",
    "    # Grab Station locations\n",
    "    sta_x, sta_z = np.genfromtxt(\"DATA/STATIONS\", dtype=float, usecols=[2, 3]).T\n",
    "    \n",
    "    # Grab Event locations\n",
    "    ev_x, ev_z = [], []\n",
    "    for i in range(1, nevents+1):\n",
    "        source_file = f\"DATA/SOURCE_{i:0>3}\"\n",
    "        with open(source_file, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        # Trying to break apart the following line\n",
    "        # 'xs = 299367.72      # source location x in meters\\n'\n",
    "        xs = float(lines[2].split(\"=\")[1].split(\"#\")[0].strip())\n",
    "        zs = float(lines[3].split(\"=\")[1].split(\"#\")[0].strip())\n",
    "\n",
    "        ev_x.append(xs)\n",
    "        ev_z.append(zs)\n",
    "        \n",
    "    # Plot SOURCES and STATIONS geometry\n",
    "    for i, (x, z) in enumerate(zip(ev_x, ev_z)):\n",
    "        plt.scatter(x, z, c=\"y\", marker=\"*\", edgecolor=\"k\", s=50)\n",
    "        plt.text(x, z, f\"S{i+1:0>2}\", fontsize=9, c=\"g\")  # SOURCE numbering starts at 1\n",
    "    for i, (x, z) in enumerate(zip(sta_x, sta_z)):\n",
    "        plt.scatter(x, z, c=\"c\", marker=\"v\", s=40, edgecolor=\"k\")\n",
    "        plt.text(x, z, f\"R{i:0>2}\", fontsize=9)\n",
    "        \n",
    "    # Finalize plot labels\n",
    "    plt.xlabel(\"X [m]\")\n",
    "    plt.ylabel(\"Z [m]\")\n",
    "    plt.xlim([0, 480E3])\n",
    "    plt.ylim([0, 480E3])\n",
    "    plt.title(\"SOURCE-RECEIVER GEOMETRY\")\n",
    "    \n",
    "    \n",
    "# Load and plot checkerboard model\n",
    "data = np.genfromtxt(\"DATA/model_velocity.dat_checker\", dtype=float, usecols=[1,2,4,5])\n",
    "chkbd_x, chkbd_z, chkbd_vp, chkbd_vs = data.T\n",
    "plt.tricontourf(chkbd_x, chkbd_z, chkbd_vp, levels=125, cmap=\"seismic_r\", alpha=0.1)\n",
    "\n",
    "# Plot sources and receivers on top\n",
    "plot_sources_receivers()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8594956-b4cb-458f-a69e-a0afc5ef5ee7",
   "metadata": {},
   "source": [
    "### b) Running the Forward Solver\n",
    "\n",
    "- We need to run the forward solver once per event (i.e., 10 times)\n",
    "- Each time we run SPECFEM, it overwrites existing files in the OUTPUT_FILES/ directory\n",
    "- In order to retain files, we need to do some file management after each forward simulation\n",
    "- We use Python for control flow but this can easily be accomplished using other languages\n",
    "- We define a re-usable function below to take care of looping through events and book keeping\n",
    "- **NOTE**: We really only have to run the mesher once to set up the database. Here we do not, but in 3D you will want to skip that step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec037c1-ac46-41ab-9c0e-6c831c5e017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fwd_mesher_solver(ntask, save_synthetics, save_forward=False):\n",
    "    \"\"\"\n",
    "    Run the mesher and solver `ntask` times. Save the resulting synthetics\n",
    "    to path `save_synthetics`. Assumes relative pathing.\n",
    "        \n",
    "    :type ntask: int\n",
    "    :param ntask: number of sources to run\n",
    "    :type save_synthetics: str\n",
    "    :param save_synthetics: relative directory name to save synthetics to\n",
    "    \"\"\"\n",
    "    print(f\"Generating synthetics for {ntask} sources\")\n",
    "    \n",
    "    # Run `ntask` forward simulations using Target model, generating 'data' for S stations. \n",
    "    for i in range(1, ntask + 1):\n",
    "        # Select the task/source to run mesher/sovler with\n",
    "        source_fid = f\"SOURCE_{i:0>3}\"\n",
    "        source_path = f\"DATA/{source_fid}\"\n",
    "        print(f\"Running mesher and solver for {source_fid}\")\n",
    "\n",
    "        # Set the correct source for SPECFEM to find\n",
    "        if os.path.exists(\"DATA/SOURCE\"):\n",
    "            os.remove(\"DATA/SOURCE\")\n",
    "        shutil.copy(source_path, \"DATA/SOURCE\")\n",
    "\n",
    "        # Run xmeshfem and xspecfem \n",
    "        ! mpirun -n 1 bin/xmeshfem2D > OUTPUT_FILES/output_mesher.txt\n",
    "        ! mpirun -n 1 bin/xspecfem2D > OUTPUT_FILES/output_solver.txt\n",
    "\n",
    "        # Move the just-generated synthetic waveforms so they don't get overwritten\n",
    "        synthetics_dir = os.path.join(source_fid, save_synthetics)\n",
    "        if os.path.exists(synthetics_dir):\n",
    "            shutil.rmtree(synthetics_dir)\n",
    "        os.makedirs(synthetics_dir)\n",
    "        for src in glob(\"OUTPUT_FILES/*.semd\"):\n",
    "            dst = os.path.join(source_fid, save_synthetics, os.path.basename(src))\n",
    "            os.rename(src, dst)\n",
    "        \n",
    "        # Save forward arrays stored on disk if requested\n",
    "        if save_forward:\n",
    "            print(f\"saving forward arrays {source_fid}\")\n",
    "            save_fwd_dir = os.path.join(source_fid, \"SAVE_FORWARD\")\n",
    "            if not os.path.exists(save_fwd_dir):\n",
    "                os.makedirs(save_fwd_dir)\n",
    "            # Save fwd arrays are the last frame and boundary conditions\n",
    "            fid_templates = [\"lastframe_elastic*.bin\", \"absorb_elastic_*.bin\"]\n",
    "            for fid in fid_templates:\n",
    "                for src in glob(f\"OUTPUT_FILES/{fid}\"):\n",
    "                    dst = os.path.join(save_fwd_dir, os.path.basename(src))\n",
    "                    os.rename(src, dst)\n",
    "        \n",
    "    print(\"Finished generating synthetics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c4bd1-baba-4270-9965-ce4937bb0e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fwd_mesher_solver(ntask=10, save_synthetics=\"TARGET\", save_forward=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b25d57-4d98-4594-972a-fab2afe47f6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3) Initial Model Synthetics\n",
    "\n",
    "- Now we'll generate synthetics through a homogeneous halfspace initial model\n",
    "- **IMPORTANT**: We need to save the forward wavefield (parameter `SAVE_FORWARD`) from the forward simulation of each $N$ events.\n",
    "- The saved forward wavefield is a snapshot of the forward wavefield at the last time step\n",
    "- The saved forward wavefield is used to reconstruct the forward wavefield during an adjoint simulation\n",
    "- For large domains (and especially in 3D), saved forward wavefields are **large** files (on the order of GB)\n",
    "- It is *not* preferable to save these large files for extended periods of time\n",
    "- We will follow that practice here by deleting the forward wavefield after each adjoint simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b1500-f7b0-471e-b29d-7a780e2a0488",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/scoped/work/day_3/inversion_example\n",
    "\n",
    "# Re-set the SPECFEM2D Par_file which is set up for the Initial model\n",
    "! cp -f DATA/Par_file_Tape2007_onerec DATA/Par_file\n",
    "\n",
    "# Edit Par_file to get the correct output files for Initial model\n",
    "! seisflows sempar -P DATA/Par_file save_model binary\n",
    "! seisflows sempar -P DATA/Par_file setup_with_binary_database 1\n",
    "! seisflows sempar -P DATA/Par_file use_existing_stations .true.\n",
    "! seisflows sempar -P DATA/Par_file save_forward .true.\n",
    "\n",
    "# Run mesher and solver for the Target model and 10 sources. \n",
    "# Also save forward arrays for subsequent adjoint simulations\n",
    "run_fwd_mesher_solver(ntask=10, save_synthetics=\"SYNTHETIC\", save_forward=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63eb49-79af-4df0-9b4f-2e04c712981e",
   "metadata": {},
   "source": [
    "## 4) Quantify Misfit, Generate Adjoint Sources for Initial Model\n",
    "\n",
    "- We want to quantify misfit for all $N \\times S$ waveforms\n",
    "- We also want to generate $N \\times S$ adjoint sources for subsequent adjoint simulations\n",
    "- We'll use a waveform difference misfit for simplicity\n",
    "- Misfit: $ \\chi = \\frac{1}{2} \\int [d(t)-s(t)]^2 dt~$\n",
    "- Adjoint Source: $f^\\dagger (t) = s(t) - d(t)$\n",
    "- We'll define a re-usable Python function to calculate misfit and generate adjoint sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589656b4-b9c9-43cf-a8ff-2c5c6bf33eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_misfit_single(data_fid, syn_fid): \n",
    "    \"\"\"\n",
    "    Quantify misfit and generate adjoint source w/ waveform difference\n",
    "    For a single source-receiver pair\n",
    "    \n",
    "    :type data_fid: str\n",
    "    :param data_fid: filename and path to data array\n",
    "    :type syn_fid: str\n",
    "    :param syn_fid: filename and path to synthetic array\n",
    "    \"\"\"\n",
    "    # Load data into NumPy arrays\n",
    "    t_data, d_data = np.loadtxt(data_fid).T\n",
    "    t_syn, d_syn = np.loadtxt(syn_fid).T\n",
    "    \n",
    "    # dt represents the time step\n",
    "    dt = t_syn[1] - t_syn[0] \n",
    "    \n",
    "    # Calculate waveform difference misfit\n",
    "    misfit = 1/2 * simps((d_data - d_syn)**2, dx=dt)\n",
    "    \n",
    "    # Create the time-amplitude array for adjoint source\n",
    "    d_adj = d_data - d_syn\n",
    "    adj_src = np.vstack((t_syn, d_adj)).T\n",
    "    \n",
    "    return misfit, adj_src    \n",
    "\n",
    "\n",
    "def quantify_misfit(misfit_file, write_adjsrc, syn_dir=\"SYNTHETIC\"):\n",
    "    \"\"\"\n",
    "    Quantify Misfit for all sources available\n",
    "    \n",
    "    :type write_misfit: str\n",
    "    :param write_misfit: file name to write misfit to\n",
    "    :type write_adjsrc: bool\n",
    "    :param write_adjsrc: choose whether or not to save adjoint sources\n",
    "    :type syn_dir: str\n",
    "    :param syn_dir: relative path to directory where synthetics are stored\n",
    "    \"\"\"\n",
    "    for src in sorted(glob(\"SOURCE_???\")):\n",
    "        print(f\"Quantifying misfit for {src}\")\n",
    "\n",
    "        # Set up directories to store misfit and adjoint sources\n",
    "        # Make sure we're writing to fresh files/directories\n",
    "        misfit_path = os.path.join(src, misfit_file)\n",
    "        if os.path.exists(misfit_path):\n",
    "            os.remove(misfit_path)\n",
    "                \n",
    "        if write_adjsrc:\n",
    "            adj_src_dir = os.path.join(src, \"ADJOINT_SOURCES\")\n",
    "            if os.path.exists(adj_src_dir):\n",
    "                shutil.rmtree(adj_src_dir)\n",
    "            os.makedirs(adj_src_dir)\n",
    "\n",
    "        # Loop through each of the synthetic waveforms to get file names\n",
    "        for syn_fid in sorted(glob(os.path.join(src, syn_dir, \"*\"))):\n",
    "            # e.g., AA.S000001.BXY.semd\n",
    "            fid_base = os.path.basename(syn_fid)\n",
    "            data_fid = os.path.join(src, \"TARGET\", fid_base)\n",
    "            \n",
    "            misfit, adj_src = quantify_misfit_single(data_fid, syn_fid)\n",
    "            print(f\"\\t{fid_base}; MISFIT={misfit:.3E}\")\n",
    "            \n",
    "            # Write misfit to file\n",
    "            with open(misfit_path, \"a\") as f:\n",
    "                f.write(f\"{misfit}\\n\")\n",
    "\n",
    "            # Write adjoint source to file\n",
    "            # Note that SPECFEM expects adjoint sources to be suffixed '.adj.\n",
    "            if write_adjsrc:\n",
    "                np.savetxt(os.path.join(adj_src_dir, fid_base.replace(\"semd\", \"adj\")), adj_src)\n",
    "                \n",
    "def plot_waveforms(t, data, labels, colors):\n",
    "    \"\"\"Re-usable function to plot synthetic waveforms\"\"\"\n",
    "    for i, d in enumerate(data):\n",
    "        plt.plot(t, d, c=colors[i], label=labels[i])\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Displacement [m]\")\n",
    "    plt.legend()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f744fde-c31e-4c23-8efe-f72bb813c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run misfit quantification for initial model\n",
    "quantify_misfit(misfit_file=\"MISFIT_INIT.txt\", write_adjsrc=True, synthetic_dir=\"SYNTHETIC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201402f6-f177-4a4e-a73c-1d5048a97dca",
   "metadata": {},
   "source": [
    "#### Understanding misfit quantification\n",
    "- For each of our $N$ sources we have quantified misfit for $S$ stations\n",
    "- Each synthetic has a corresponding adjoint source, which is stored in `SOURCE_???/ADJOINT_SOURCE`\n",
    "- Each adjoint source is equal to the waveform difference between data and synthetic\n",
    "- Each adjoint source has a corresponding misfit value\n",
    "- Misfit values are stored in a text file which can be summed to calculate the overall **event misfit**\n",
    "- The adjoint sources will be used to run $N$ adjoint simulations\n",
    "- The misfit value will be used to determine if misfit is reduced during the line search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a85d25-85a3-4719-93e6-8c09da4ee6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can take a look at the files we just created\n",
    "! ls SOURCE_001\n",
    "! echo \n",
    "! echo \"> ADJOINT SOURCES\"\n",
    "! ls SOURCE_001/ADJOINT_SOURCES\n",
    "! echo \n",
    "! echo \"> SOURCE_001/ADJOINT_SOURCES/AA.S000000.BXY.adj\"\n",
    "! head SOURCE_001/ADJOINT_SOURCES/AA.S000000.BXY.adj\n",
    "! echo\n",
    "! echo \"> SOURCE_001/MISFIT_INIT.txt\"\n",
    "! head SOURCE_001/MISFIT_INIT.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f2a77-b0e5-4531-b260-5080781e6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an example of data, synthetic and adjoint source\n",
    "t_init, d_init = np.loadtxt(\"SOURCE_001/SYNTHETIC/AA.S000000.BXY.semd\").T\n",
    "t_true, d_true = np.loadtxt(\"SOURCE_001/TARGET/AA.S000000.BXY.semd\").T\n",
    "t_adjs, d_adjs = np.loadtxt(\"SOURCE_001/ADJOINT_SOURCES/AA.S000000.BXY.adj\").T\n",
    "\n",
    "plot_waveforms(t=t_init, data=[d_init, d_true, d_adjs],\n",
    "               labels=[\"initial\", \"target\", \"adjsrc\"],\n",
    "               colors=[\"r\", \"k\", \"g\"])\n",
    "\n",
    "plt.title(\"Initial vs. Target Model Synthetics\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e71333a-b4e3-4c59-8196-4fe63612bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveforms(t=t_init, data=[d_init, d_true, d_adjs],\n",
    "               labels=[\"initial\", \"target\", \"adjsrc\"],\n",
    "               colors=[\"r\", \"k\", \"g\"])\n",
    "plt.xlim([45,145])\n",
    "plt.title(\"Initial vs. Target Model Synthetics\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2990d06-1b94-4524-890f-925745db5688",
   "metadata": {},
   "source": [
    "## 5) Run Adjoint Simulations for Event Kernels\n",
    "\n",
    "- Now we need to run the adjoint simulations to generate event kernels\n",
    "- Event kernels tell us what parts of the model are sensitive to the misfit function for **EACH** event\n",
    "- Adjoint simulations take $S$ adjoint sources as input \n",
    "- **NOTE**: We need to place the adjoint sources in the correct location and also tell SPECFEM that we are running an adjoint simulation\n",
    "- SPECFEM expects adjoint sources in the `SEM/` directory, and formatted exactly the same as its output synthetics\n",
    "- We define a Python function below to run the adjoint solver and take care of book keeping for adjoint sources and kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee116fa-5019-4984-b78f-606a676beb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_adj_solver():\n",
    "    \"\"\"\n",
    "    Counterpart to `run_fwd_mesher_solver`, runs adjoint simulations for `ntask` events\n",
    "    and saves the resulting kernels. Assumes relative paths\n",
    "    \"\"\"\n",
    "    ntask = len(glob(\"SOURCE_???\"))\n",
    "    print(f\"Running adjoint simulations for {ntask} events\")\n",
    "    \n",
    "    for i in range(1, ntask + 1):\n",
    "        # Choose the task/source to run mesher/sovler with\n",
    "        source_fid = f\"SOURCE_{i:0>3}\"\n",
    "        source_path = f\"DATA/{source_fid}\"\n",
    "        print(f\"Running adjoint simulation for {source_fid}\")\n",
    "\n",
    "        # Set the correct source for SPECFEM to find\n",
    "        if os.path.exists(\"DATA/SOURCE\"):\n",
    "            os.remove(\"DATA/SOURCE\")\n",
    "        shutil.copy(source_path, \"DATA/SOURCE\")\n",
    "                \n",
    "        # Symlink adjoint sources so SPECFEM can find them\n",
    "        if os.path.islink(\"SEM\"):\n",
    "            os.remove(\"SEM\")\n",
    "        os.symlink(os.path.join(source_fid, \"ADJOINT_SOURCES\"), \"SEM\")\n",
    "        \n",
    "        # Copy the saved forward array so that SPECFEM can find it\n",
    "        for src in glob(os.path.join(source_fid, \"SAVE_FORWARD\", \"*\")):\n",
    "            dst = os.path.join(\"OUTPUT_FILES\", os.path.basename(src))\n",
    "            if os.path.exists(dst):\n",
    "                os.remove(dst)\n",
    "            shutil.copy(src, dst)\n",
    "            \n",
    "        # Run the adjoint simulation\n",
    "        ! mpirun -n 1 bin/xspecfem2D > OUTPUT_FILES/adjoint_solver.txt\n",
    "        \n",
    "        # Move the resulting event kernel to disk\n",
    "        kernel_dir = os.path.join(source_fid, \"KERNELS\")\n",
    "        if os.path.exists(kernel_dir):\n",
    "            shutil.rmtree(kernel_dir)\n",
    "        os.makedirs(kernel_dir)\n",
    "        for src in glob(\"OUTPUT_FILES/*kernel.bin\"):\n",
    "            dst = os.path.join(kernel_dir, os.path.basename(src))\n",
    "            os.rename(src, dst)\n",
    "            \n",
    "    print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee16e72-3d2e-48b2-a7f5-f9f5e4f5813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Par_file to run an adjoint simulation (type 3) \n",
    "# and output kernels in expected output (FORTRAN binary)\n",
    "! seisflows sempar -P DATA/Par_file simulation_type 3\n",
    "! seisflows sempar -P DATA/Par_file save_ASCII_kernels .false.\n",
    "\n",
    "# Run adjoint simluation for each N sources. This may take a while\n",
    "run_adj_solver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af05d6e0-7607-453a-a681-2b78f44633b7",
   "metadata": {},
   "source": [
    "## 6) Sum Event Kernels and Scale Gradient\n",
    "\n",
    "- Now we have $N$=10 event kernels, each representing misfit sensitivity for each of the $N$ events\n",
    "- We need to sum the *event kernels* into a *misfit kernel*, which represents misfit sensitivity for **all** $N$ events\n",
    "- We can use the `xcombine_sem` executable to sum these kernels\n",
    "- We will also need to scale the misfit kernel before perturbing the initial model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823aa354-b454-4595-8e9a-a114fbeb19ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to tell SPECFEM where all our kernel files are by \n",
    "# listing paths in an input file\n",
    "with open(\"kernel_paths.txt\", \"w\") as f:\n",
    "    for fid in sorted(glob(\"SOURCE_???/KERNELS\")):\n",
    "        f.write(f\"{os.path.abspath(fid)}\\n\")\n",
    "\n",
    "# Make a directory to store gradient files\n",
    "! mkdir GRADIENT\n",
    "\n",
    "# mpirun -n NPROC bin/xcombine_sem KERNEL_NAMES INPUT_FILE OUTPUT_DIR*\n",
    "! mpirun -n 1 bin/xcombine_sem alpha_kernel,beta_kernel kernel_paths.txt GRADIENT \n",
    "\n",
    "# Rename 'alpha' to Vp and 'beta' to Vs for easier name recognition\n",
    "for src in glob(\"GRADIENT/*\"):\n",
    "    if \"alpha\" in src:\n",
    "        os.rename(src, src.replace(\"alpha\", \"vp\"))\n",
    "    elif \"beta\" in src:\n",
    "        os.rename(src, src.replace(\"beta\", \"vs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc284de-0be7-455b-92cc-03b91c5584f5",
   "metadata": {},
   "source": [
    "### a) Visualizing the Event Kernel\n",
    "\n",
    "- We can visualize the gradient using SeisFlows utilities\n",
    "- Note that this visualization technique is only viable for SPECFEM2D\n",
    "- Gradient amplitudes are stored in the output Fortran binary files\n",
    "- We only plot the Vs Kernel here but the Gradient is a linear array of Vp and Vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2154d-4487-4de3-8188-0bc7834d60ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell we'll scale the gradient (Vp and Vs only) by GTG^-1\n",
    "x = read_fortran_binary(\"DATA/proc000000_x.bin\")\n",
    "z = read_fortran_binary(\"DATA/proc000000_z.bin\")\n",
    "vs_kernel = read_fortran_binary(\"GRADIENT/proc000000_vs_kernel.bin\")\n",
    "\n",
    "boundary_value = 2E-10  # <- change this value to adjust the colorscale\n",
    "\n",
    "# Plot the kernel\n",
    "plt.tricontourf(x, z, vs_kernel, levels=125, cmap=\"seismic_r\", \n",
    "                vmin=-1*boundary_value, vmax=boundary_value)\n",
    "plt.colorbar()\n",
    "\n",
    "plot_sources_receivers()\n",
    "plt.title(\"Gradient Vs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e6be4-b9f4-4d85-9d23-61e67fea378f",
   "metadata": {},
   "source": [
    "#### Understanding the above figure\n",
    "\n",
    "- Above we are seeing the Misfit kernel for the parameter Vs\n",
    "- The misfit kernel represents sensitivity of the misfit function to changes in model parameter Vs\n",
    "- Red colors tell us that the inital model is **too fast** (i.e., we need to slow down the initial model)\n",
    "- Blue colors tell us that the initial model is **too slow** (i.e., we need to speed up the initial model)\n",
    "- We can see large amplitudes directly around source locations (e.g., S01 and S09 at the bottom)\n",
    "- These amplitudes are due to the numerical discretization of our grid, and the fact that we implement point source forces\n",
    "- We can use regularization to remove the strong influence of the near-source region\n",
    "- Our chosen regularization technique is smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b54ad08-0b1d-49d4-95d7-d8924d8c578f",
   "metadata": {},
   "source": [
    "## 7) Smoothing/Regularizing Kernels\n",
    "\n",
    "- We can use regularization to smooth out the gradient to get a more conservative picture of model update\n",
    "- We use the `xsmooth_sem` executable to smooth our kernels\n",
    "- We should choose smoothing length based on the shortest period of our data\n",
    "- Because we know the target model, we smooth conservatively to the length scale of the checkerboards ($\\Gamma$=50km)\n",
    "- The SPECFEM smoothing code convolves the kernel with a Gaussian. We are allowed to choose the half-width of the Gaussian\n",
    "- The relationship between half-width and full-width is $\\Gamma\\approx2.355\\sigma$, so we choose $\\sigma$=20km\n",
    "\n",
    " The usage of `xsmooth_sem` is given as\n",
    " ```bash\n",
    " USAGE:  mpirun -np NPROC bin/xsmooth_sem SIGMA_H SIGMA_V KERNEL_NAME INPUT_DIR OUPUT_DIR GPU_MODE\n",
    " ```\n",
    " We will need to choose values and directories to make this work\n",
    "  - `SIGMA_H`: Horizontal smoothing length [m] representing the horizontal half-width of the Gaussian  \n",
    "  - `SIGMA_Z`: Vertical smoothing length [m] representing the vertical half-width of the Gaussian  \n",
    "  - `KERNEL_NAME`: The name of the kernel we want to smooth. Must match filename, so `proc000000_vs_kernel.bin` will correspond to kernel name `vs_kernel`  \n",
    "  - `INPUT_DIR`: where SPECFEM can find the kernel files\n",
    "  - `OUTPUT_DIR`: Where SPECFEM should output the SMOOTHED kernels \n",
    "  - `GPU_MODE`: Use GPU acceleration to speed up the smoothing operation (.true. or .false.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce8b829-3bd6-4b80-99db-332d9c0e8ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECFEM Requires that some of the model files be discoverable alongside the kernels\n",
    "! cp -f GRADIENT/*.bin DATA/\n",
    "\n",
    "! mpirun -n 1 bin/xsmooth_sem 20000 20000 vs_kernel DATA/ GRADIENT/ .false.\n",
    "! mpirun -n 1 bin/xsmooth_sem 20000 20000 vp_kernel DATA/ GRADIENT/ .false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aefc2d8-6e52-4c38-9151-a73c2ae05255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The smoothing operation has created new files with the 'smooth' tag\n",
    "vs_kernel_smooth = read_fortran_binary(\"GRADIENT/proc000000_vs_kernel_smooth.bin\")\n",
    "\n",
    "boundary_value = 8E-11  # <- change this value to adjust the colorscale\n",
    "\n",
    "# Plot the kernel\n",
    "plt.tricontourf(x, z, vs_kernel_smooth, levels=125, cmap=\"seismic_r\", \n",
    "                vmin=-1*boundary_value, vmax=boundary_value)\n",
    "plt.colorbar()\n",
    "\n",
    "plot_sources_receivers()\n",
    "plt.title(\"Smoothed Gradient Vs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f145bc9-1270-44d8-9bba-262a1bc29700",
   "metadata": {},
   "source": [
    "#### Understanding the above figure\n",
    "\n",
    "- Above we see the smoothed misfit kernel\n",
    "- We have applied smoothing using a 2D Gaussian with half width equal to 20km\n",
    "- The regularization has removed the small-scale heterogeneity present in the raw gradient\n",
    "- The colors still represent the same quantities as before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec5ea7a-91fe-4276-ac4f-616a5a783b48",
   "metadata": {},
   "source": [
    "## 8) Scaling the Gradient\n",
    "\n",
    "- Again we'll need to **scale** the gradient before using it to perturb the initial model\n",
    "- As in Day 3a, we'll scale the gradient by [G$^T$G]$^{-1}$\n",
    "- We can then perturb the initial model by the scaled gradient to recover new synthetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31242af4-80e2-4e74-b54d-115eda25c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the regularized kernel\n",
    "vp_kernel = read_fortran_binary(\"GRADIENT/proc000000_vs_kernel_smooth.bin\")\n",
    "vs_kernel = read_fortran_binary(\"GRADIENT/proc000000_vs_kernel_smooth.bin\")\n",
    "\n",
    "# The Gradient is a linear vector of kernels for each parameter\n",
    "gradient = np.hstack((vp_kernel, vs_kernel))\n",
    "\n",
    "# Calculate GTG^-1\n",
    "gtg = np.dot(gradient, gradient)\n",
    "gtg_inverse = gtg ** -1 \n",
    "print(f\"GTG^-1 = {gtg_inverse:.2f}\")\n",
    "\n",
    "# Scaling the gradient by GTG^-1\n",
    "gradient = gradient * gtg_inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f125870-b51d-4c6f-948b-b43d2eac9ce5",
   "metadata": {},
   "source": [
    "## 9) Perturbing the Initial Model\n",
    "\n",
    "- We can perturb the initial model with the gradient to generate an update model ($m_{try}$)\n",
    "- We'll use this updated model to run forward simulations\n",
    "- We **only** update seismic velocity Vp and Vs. However during your own research, other quantities may be updated.\n",
    "- Users will need to determine what model parameters their misfit function is sensitive to\n",
    "- **Objective**: Quantify misfit of the new synthetics to determine if misfit has been reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e53b3-1fb4-415a-b3fc-1a1b3a14a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will separate model files to keep things clean\n",
    "! rm -rf MODEL_INIT\n",
    "! mkdir MODEL_INIT\n",
    "! rm -rf MODEL_01\n",
    "! mkdir MODEL_01\n",
    "\n",
    "# These files define a SPECFEM2D model. SPECFEM3D models will differ\n",
    "for tag in [\"x\", \"z\", \"rho\", \"vp\", \"vs\", \"NSPEC_ibool\", \"jacobian\"]:\n",
    "    src = f\"DATA/proc000000_{tag}.bin\"\n",
    "    # Save the initial model to disk\n",
    "    dst = f\"MODEL_INIT/{os.path.basename(src)}\"\n",
    "    shutil.copy(src, dst)\n",
    "    # Copy to Model 01 which will be overloaded by new parameters\n",
    "    dst = f\"MODEL_01/{os.path.basename(src)}\"\n",
    "    shutil.copy(src, dst)\n",
    "    \n",
    "# Load the initial model velocity so we can overload them\n",
    "model_init_vp = read_fortran_binary(\"MODEL_INIT/proc000000_vp.bin\")\n",
    "model_init_vs = read_fortran_binary(\"MODEL_INIT/proc000000_vs.bin\")\n",
    "\n",
    "# Split the gradient by parameter\n",
    "n = len(gradient) // 2\n",
    "gradient_vp = gradient[:n]\n",
    "gradient_vs = gradient[n:]\n",
    "\n",
    "# Perturb the initial model by the gradient\n",
    "model_01_vp = model_init_vp - gradient_vp\n",
    "model_01_vs = model_init_vs - gradient_vs\n",
    "\n",
    "# OVERWRITE Vp and Vs for Model 01 with perturbed model parameters\n",
    "write_fortran_binary(model_01_vp, \"MODEL_01/proc000000_vp.bin\")\n",
    "write_fortran_binary(model_01_vs, \"MODEL_01/proc000000_vs.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502fc11-b50e-48aa-8ae9-c2638bbccbbb",
   "metadata": {},
   "source": [
    "### a) Checking Model Parameters\n",
    "\n",
    "- We can quickly determine if the update model is acceptable by checking min and max values\n",
    "- We use external knowledge to quantify whether the new model is acceptable\n",
    "- For example we know we cannot have negative velocity values for typical wavespeeds in Earth structure\n",
    "- External geological evidence might also help constrain expected velocity values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456cb38-2e72-49f1-9a11-85f676ab6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MODEL INIT Vs_min = {model_init_vs.min()}\")\n",
    "print(f\"MODEL INIT Vs_max = {model_init_vs.max()}\")\n",
    "print(f\"\\nMODEL TRY Vs_min = {model_01_vs.min()}\")\n",
    "print(f\"MODEL TRY Vs_max = {model_01_vs.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df37bd79-3462-4a3f-bd14-0c0ee40b477f",
   "metadata": {},
   "source": [
    "Already we see that our velocity values are way out of spec. We will need to manually step back our gradient. \n",
    "In a real seismic inversion, this would be algorithmically determined, but for the sake of brevity we will\n",
    "simply scale back our gradient until we reach acceptable perturbation levels. Here we limit the largest value of $\\alpha$ to be roughly 10\\% of the initial model value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba695f94-cb08-47dd-adaa-8035dbbde91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe guard the gradient from overreaching\n",
    "max_alpha = model_init_vs.mean() * 0.1  \n",
    "gradient /= gradient.max()  # reset gradient to be scaled to 1\n",
    "gradient *= max_alpha  # set a new alpha value as 10% of the velocity model\n",
    "\n",
    "# Create new updated model parameters !!! WHY IS THIS POSITIVE AND NOT NEGATIVE? !!!\n",
    "model_01_vp = model_init_vp + gradient_vp\n",
    "model_01_vs = model_init_vs + gradient_vs\n",
    "\n",
    "# OVERWRITE Vp and Vs for Model 01 with perturbed model parameters\n",
    "write_fortran_binary(model_01_vp, \"MODEL_01/proc000000_vp.bin\")\n",
    "write_fortran_binary(model_01_vs, \"MODEL_01/proc000000_vs.bin\")\n",
    "\n",
    "print(f\"MODEL TRY Vs_min = {model_01_vs.min()}\")\n",
    "print(f\"MODEL TRY Vs_max = {model_01_vs.max()}\")\n",
    "\n",
    "# Plot the updated model\n",
    "plt.tricontourf(x, z, model_01_vs, levels=125, cmap=\"RdYlBu\")\n",
    "plt.colorbar()\n",
    "\n",
    "plot_sources_receivers()\n",
    "plt.title(\"Model 01 Trial 1 Vs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e07abdc-e9e5-4b51-ab88-6f99c96490e5",
   "metadata": {},
   "source": [
    "## 10) Run Forward Simulations with Updated Model\n",
    "\n",
    "- Now that we have a perturbed model (Model 01) we can use it to run forward simulations\n",
    "- We can calculate misfit for each of the new synthetics \n",
    "- We can compare the overall misfit of the initial model to Model 01\n",
    "- **Objective**: determine if we have reduced waveform misfit through our model perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa3506-55c3-4695-8d8c-f8260cc103d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the correct velocity model where SPECFEM expects it\n",
    "for tag in [\"x\", \"z\", \"rho\", \"vp\", \"vs\", \"NSPEC_ibool\", \"jacobian\"]:\n",
    "    src = f\"MODEL_01/proc000000_{tag}.bin\"\n",
    "    dst = f\"DATA/proc000000_{tag}.bin\"\n",
    "    if os.path.exists(dst):\n",
    "        os.remove(dst)\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "# Reset the simulation type to forward, since we changed it during the adjoint simulation\n",
    "! seisflows sempar -P DATA/Par_file simulation_type 1\n",
    "! seisflows sempar -P DATA/Par_file model gll\n",
    "\n",
    "run_fwd_mesher_solver(ntask=10, save_synthetics=\"SYNTHETIC_01\", save_forward=False)\n",
    "quantify_misfit(misfit_file=\"MISFIT_01.txt\", write_adjsrc=False, syn_dir=\"SYNTHETIC_01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0747efad-cd1d-496a-aa52-885dc03afe1b",
   "metadata": {},
   "source": [
    "### a) Visualizing Waveform Differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b01e11-ec0f-40cd-a5c7-39c74bc576b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an example of data, synthetic and adjoint source\n",
    "t_init, d_init = np.loadtxt(\"SOURCE_001/SYNTHETIC/AA.S000000.BXY.semd\").T\n",
    "t_true, d_true = np.loadtxt(\"SOURCE_001/TARGET/AA.S000000.BXY.semd\").T\n",
    "t_m01, d_m01 = np.loadtxt(\"SOURCE_001/SYNTHETIC_01/AA.S000000.BXY.semd\").T \n",
    "\n",
    "plot_waveforms(t=t_init, data=[d_init, d_true, d_m01],\n",
    "               labels=[\"initial\", \"target\", \"update\"],\n",
    "               colors=[\"r\", \"k\", \"b\"])\n",
    "\n",
    "plt.title(\"Initial vs. Updated Model Synthetics\")\n",
    "plt.xlim([45, 145])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63f68d1-0c03-4e2d-827a-1f441c8f031c",
   "metadata": {},
   "source": [
    "## 11) Comparing Misfit between Initial and Updated models\n",
    "- Now we have two files containing misfit, one for the initial model, and one for the updated model (M01)\n",
    "- Each line in the misfit file corresponds to the overall misfit for a single event\n",
    "- We can compare them by taking the average of all lines in the misfit file\n",
    "- Misfit: $ \\chi = \\frac{1}{2} \\int [d(t)-s(t)]^2 dt~$\n",
    "\n",
    "!!! TOTAL MISFIT HERE !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c4536-4267-4d42-9534-91af101865d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate misfit from each source\n",
    "misfit_init, misfit_m01 = [], []\n",
    "\n",
    "for src in sorted(glob(\"SOURCE_???\")):\n",
    "    m_init = np.loadtxt(os.path.join(src, \"MISFIT_INIT.txt\"))\n",
    "    m_01 = np.loadtxt(os.path.join(src, \"MISFIT_01.txt\"))\n",
    "    \n",
    "    misfit_init.append(m_init.sum() / len(m_init))\n",
    "    misfit_m01.append(m_01.sum() / len(m_01))\n",
    "    \n",
    "total_misfit_init = sum(misfit_init) / len(misfit_init)\n",
    "total_misfit_m01 = sum(misfit_m01) / len(misfit_m01)\n",
    "\n",
    "print(f\"MISFIT INITIAL MODEL = {total_misfit_init}\")\n",
    "print(f\"MISFIT UPDATED MODEL = {total_misfit_m01}\")\n",
    "print(f\"MISFIT REDUCED? -> {bool(total_misfit_init > total_misfit_m01)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6959bfa-07b7-4d38-8365-1e02d407f959",
   "metadata": {},
   "source": [
    "## 12) Final Thoughts\n",
    "\n",
    "!!! TO DO !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7225260-bed6-4141-92cd-798017472db8",
   "metadata": {},
   "source": [
    "# Automating An Inversion using SeisFlows\n",
    "\n",
    "- Of course, now that we have gone through the rigorous manual exercise of updating a velocity model, we will show how SeisFlows automates this procedure.\n",
    "- Under the hood, SeisFlows essentialy performs what we just did, scaling the velocity model, re-running forward simulations and comparing misfit values\n",
    "- SeisFlows contains a built-in optimization library, which features gradient-descent, non-linear conjugate gradient (NLCG), and L-BFGS nonlinear optimization alogirthms\n",
    "- This library takes care of the scaling of the gradient, automating the line search and model update\n",
    "- Misfit is either calculated with the default preprocessing module, or using Pyatoa, a software designed specifically for waveform misfit quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80930e4-dee7-464b-98c0-18d6618ceb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf /home/scoped/work/day_3/sfexample_2\n",
    "! mkdir -p /home/scoped/work/day_3/sfexample_2\n",
    "%cd /home/scoped/work/day_3/sfexample_2\n",
    "\n",
    "! seisflows examples setup 2 -r /home/scoped/specfem2d --niter 1 --ntask 10 --nsta 10 --with_mpi\n",
    "! seisflows par smooth_h 20000.\n",
    "! seisflows par smooth_v 20000.\n",
    "! seisflows submit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44fb922-5577-45e5-bbe1-438f6562b7f7",
   "metadata": {},
   "source": [
    "-------------\n",
    "\n",
    "The task will be finished when you see the log message:\n",
    "\n",
    "```bash\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "                             COMPLETE ITERATION 01                              \n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "2022-09-16 21:25:38 (I) | setting current iteration to: 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f03f2-152c-48cc-9c58-88b78961e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"> output/ contains models, gradients, etc.\"\n",
    "! ls output\n",
    "! echo\n",
    "\n",
    "! echo \"> MODEL directories contain SPECFEM formatted model files\"\n",
    "! ls output/MODEL_INIT\n",
    "! echo\n",
    "\n",
    "! echo \"> GRADIENT directories contain regularized misfit kernels\"\n",
    "! ls output/GRADIENT_01\n",
    "! echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea91f98-8b87-47c8-be18-08f3c7597ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models/gradients can be plotted directly from the command line\n",
    "! seisflows plot2d MODEL_01 vs --savefig m_01_vs.png\n",
    "Image(\"m_01_vs.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
