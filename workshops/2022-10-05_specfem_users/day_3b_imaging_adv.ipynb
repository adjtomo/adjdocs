{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347bc0f7-6dbe-454c-a95a-8469d8efe1c2",
   "metadata": {},
   "source": [
    "# SPECFEM Users Workshop -- Day 3 (Oct. 7, 2022)\n",
    "\n",
    "# TO DO (ctrl+f `!!!`):\n",
    "- Add Day 3 slides (this cell)\n",
    "- Check model update equation (Section 3)\n",
    "- Explain difference between sensitivity kernel, misfit kernel, event kernel, gradient (section 3)\n",
    "\n",
    "\n",
    "\n",
    "## Part 3: Seismic Imaging\n",
    "\n",
    "- In this notebook we will bring all of the previous material together run a full seismic inversion to update a starting model. \n",
    "- We will generate a misfit kernel as shown in Day 2\n",
    "- We use the misfit kernel to update a starting homogeneous halfspace model\n",
    "- This new model is used to generate forward simulations, as shown in Day 1\n",
    "- Waveforms from the initial model and updated model are compared to the True model\n",
    "- Waveform misfit, introduced in Day 2, is used to determine if the model update improved waveform fit\n",
    "- **Objective**: Illustrate model updates in the context of imaging. Relate manual tasks with nonlinear optimization algorithms and line searches\n",
    "- These instructions should be run from inside the Docker container, using Jupyter Lab (see *Docker Preamble* in Day 0). \n",
    "\n",
    "-----------\n",
    "\n",
    "**Relevant Links:** \n",
    "- Day 3 Slides !!! ADD THIS !!!\n",
    "- Today's Notebook: https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/day_3a_imaging.ipynb\n",
    "- Completed Notebook: https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_3a_imaging.ipynb\n",
    "- Day 0 Notebook (Container Testing): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_0_container_testing.ipynb\n",
    "- Day 1A Notebook (Intro SPECFEM): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_1a_intro_specfem2d.ipynb\n",
    "- Day 1B Notebook (Fwd. Simulations): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_1b_forward_simulations.ipynb\n",
    "- Day 2A Notebook (Adj. Simulations): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_2a_kernels.ipynb\n",
    "\n",
    "**Jupyter Quick Tips:**\n",
    "\n",
    "- **Run cells** one-by-one by hitting the $\\blacktriangleright$ button at the top, or by hitting `Shift + Enter`\n",
    "- **Run all cells** by hitting the $\\blacktriangleright\\blacktriangleright$ button at the top, or by running `Run -> Run All Cells`\n",
    "- **Currently running cells** that are still processing will have a `[*]` symbol next to them\n",
    "- **Finished cells** will have a `[1]` symbol next to them. The number inside the brackets represents what order this cell has been run in.\n",
    "- Commands that start with `!` are Bash commands (i.e., commands you would run from the terminal)\n",
    "- Commands that start with `%` are Jupyter Magic commands.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fed39d-3309-4957-b254-66c67ca131be",
   "metadata": {},
   "source": [
    "## 1) Background\n",
    "\n",
    "!!! TO DO !!!\n",
    "Potential topics:\n",
    "- Nonlinear optimization algorithms\n",
    "- Line searches\n",
    "- Model perturbations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0acd55c-e9b3-4448-a327-ea23b797d6a5",
   "metadata": {},
   "source": [
    "## 2) Setting Up a SPECFEM2D Working Directory\n",
    "\n",
    "- We want to set up a clean working directory to run SPECFEM2D inside. This will help us preserve our cloned repository and reduce file clutter.\n",
    "- We will use SeisFlows to automate an inversion workflow **up to** kernel generation, to save time.\n",
    "- SeisFlows will run a forward simulation, calculate misfit, and run an adjoint simulation.\n",
    "- Experimental setup is: one source, one receiver, starting model is a homogeneous halfspace, target model is a perturbation checkerboard.\n",
    "- **Objective**: Generate a misfit kernel which we can use to update our model manually. \n",
    "- **NOTE:** We will be doing all our work in the directory /home/scoped/work/day_3. All the following cells assume that we are in this directory, so you must evaluate the '%cd' command to ensure that cells work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bfc4ea-a94a-4d4d-9453-a7e11c0201d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from IPython.display import Image\n",
    "from scipy.integrate import simps\n",
    "from seisflows.tools.specfem import Model, read_fortran_binary, write_fortran_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c386f6-0c75-4d44-b532-a1455eefd1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we're in an empty working directory\n",
    "! mkdir -p /home/scoped/work/day_3/sfexample_2\n",
    "%cd /home/scoped/work/day_3/sfexample_2\n",
    "\n",
    "# Run the example and stop after adjoint simulation\n",
    "! seisflows examples setup 2 -r /home/scoped/specfem2d --event_id 1 --nsta 1 --niter 1 --with_mpi\n",
    "! seisflows par stop_after evaluate_gradient_from_kernels\n",
    "! seisflows submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e6f223-1faa-4eb5-88c6-9f629dd65c2e",
   "metadata": {},
   "source": [
    "-----------\n",
    "\n",
    "You will know that this workflow has completed successfully after the final log message   \n",
    "\n",
    "```bash\n",
    "2022-09-16 19:57:07 (I) | stop workflow at `stop_after`: evaluate_gradient_from_kernels\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f670a96-8911-4e5a-8d0e-f81c0b8f3842",
   "metadata": {},
   "source": [
    "## 3) Manually Updating a Velocity Model\n",
    "\n",
    "- We will use this gradient that was generated using SeisFlows to update our initial model. \n",
    "- With only have one source receiver pair, we can immediately check if the misfit of the waveforms has decreased by solving for $\\chi$.\n",
    "- In SeisFlows, we treat models and gradients as linear arrays, so model update can be memory-intensive, but is not CPU intensive.\n",
    "\n",
    "!!! CHECK THIS EQUATION !!!\n",
    "\n",
    "The Model update equation can be simple as: $m_{i+1} = m_{i} - \\alpha \\times g$ \n",
    "Where $m_{i}$ is the current model, $m_{i+1}$ is the updated model, $g$ is the gradient and $\\alpha$ is a scale factor.\n",
    "\n",
    "### Initial Model ($m_i$) and Target Model ($m_{true}$)\n",
    "\n",
    "- The **initial/starting** model is our homogeneous halfspace model\n",
    "- The homogeneous halfspace model defines a region with P-wave velocity 5.8km/s and S-wave velocity 3.5km/s. \n",
    "- This is the same model that we looked at in Day 1B and 2A \n",
    "- The **target/true** model is a checkerboard perturbation model\n",
    "- Perturbations are roughly $\\pm$10\\% of the initial homogeneous halfspace Vp and Vs models\n",
    "- The target model is used to generate 'data', which mimics real-world observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef67b11a-4bf9-41a2-882e-8231398534c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the initial model binary files, plot\n",
    "m_init = Model(\"output/MODEL_INIT\")\n",
    "print(f\"INITIAL MODEL\\n{m_init.model}\")\n",
    "m_init.plot2d(\"vs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc9635-8d46-4ef3-9729-1d444fc96153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the target model which has generated 'data'\n",
    "m_true = Model(\"output/MODEL_TRUE\")\n",
    "print(f\"TARGET MODEL\\n{m_true.model}\")\n",
    "m_true.plot2d(\"vs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6f760a-54e5-4e74-a0d1-abe49779854a",
   "metadata": {},
   "source": [
    "### Misfit Kernel / Gradient ($g$)\n",
    "\n",
    "!!! TO DO explain difference between sensitivity kernel, misfit kernel, event kernel, gradient !!!\n",
    "\n",
    "- The gradient was generated by the interaction of our forward and adjoint wavefields.\n",
    "- It represents the gradient of the misfit function and provides a search direction for model update.\n",
    "- This gradient was generated using only one source-receiver pair\n",
    "- This gradient was smoothed with a 2D Gaussian of vertical and horizontal half-widths of 5km\n",
    "- This gradient is very similar to what we recovered after smoothing our misfit kernel in Day 2\n",
    "- **NOTE**: Because the Gradient output directory does not contain coordinate information, we need to grab it from the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88a09e0-3012-4c12-8edd-e74f771c4173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Gradient binary files\n",
    "gradient = Model(\"output/GRADIENT_01\")\n",
    "\n",
    "# Assign coordinate information which is used for plotting\n",
    "gradient.coordinates = {}\n",
    "gradient.coordinates[\"x\"] = m_init.coordinates[\"x\"]\n",
    "gradient.coordinates[\"z\"] = m_init.coordinates[\"z\"]\n",
    "\n",
    "print(f\"GRADIENT\\n{gradient.model}\")\n",
    "gradient.plot2d(\"vs_kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba284cc-4d03-4786-8041-cf6e0834d038",
   "metadata": {},
   "source": [
    "### Updated Model ($m_{i+1}$)\n",
    "\n",
    "- The updated model can be found by scaling the gradient and adding the negative gradient to the initial model. \n",
    "- Remember that the gradient represents maximum change, and since we are solving a minimization problem, we want to use the inverse gradient.\n",
    "- The updated model is represented by equation: $m_{i+1} = m_{i} - \\alpha \\times g$ \n",
    "- Here we do **not** scale the gradient, so $\\alpha$==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf712794-451d-4390-a08a-bb340695d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the SeisFlows Model class to update the model directly\n",
    "m_update = m_init.copy()\n",
    "\n",
    "# No scaling is applied here\n",
    "m_update.update(vector=m_init.vector - gradient.vector)\n",
    "\n",
    "print(m_update.model)\n",
    "\n",
    "m_update.plot2d(\"vs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdf5112-9f54-4323-8bc2-13efcff4ab57",
   "metadata": {},
   "source": [
    "#### Understanding the updated model\n",
    "- Don't let the color scale fool you. Look at the values in the title to see how little the gradient changed the model\n",
    "- We can see that because the gradient is **not** well scaled, the model updates only make slight changes to the Vs model ($\\pm.0001$m/s give or take). \n",
    "- In order to make appreciable changes to the starting model, we need the **scale** the gradient. \n",
    "- There are many algorithms which provide scaling estimates for the gradient. \n",
    "- One thing we can try, is scaling by GTG$^{-1}$ (i.e,. the inverse of the dot product of the gradient itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd2839-d09f-4cba-b02c-469ed2977845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caclulating GTG^-1\n",
    "gtg = np.dot(gradient.vector, gradient.vector)\n",
    "gtg_inverse = gtg ** -1 \n",
    "\n",
    "print(f\"GTG^-1 = {gtg_inverse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4941378-21f9-4869-998e-25f57bb575c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the starting model with the scaled gradient\n",
    "m_update = m_init.copy()\n",
    "m_update.update(vector=m_init.vector - (gtg_inverse * gradient.vector))\n",
    "\n",
    "print(m_update.model)\n",
    "\n",
    "m_update.plot2d(\"vs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ccb991-0bec-42de-8b05-9c3cb8df55a6",
   "metadata": {},
   "source": [
    "#### Understanding the newly scaled model update\n",
    "- The actual volumetric region added to the initial model is the same. We have only changed the amplitude\n",
    "- The gradient is now more well scaled, and has updated our velocity model at most 25m/s. \n",
    "- We can try to use this updated velocity model to generate **new** synthetics\n",
    "- We expect that the waveforms generated from this updated model will differ from our initial model synthetics\n",
    "- We can compare waveform misfit for the new model synthetics against the true model to determine it's misfit value\n",
    "- If misfit has reduced from the original model, then we're getting somewhere!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec85abf8-6e29-45e1-afb0-203e4a8d55b2",
   "metadata": {},
   "source": [
    "## 4) Forward Simulations w/ Updated Model\n",
    "\n",
    "- We now have an updated model stored in the Python parameter `m_update`. \n",
    "- We'll use this updated model to generate a new set of synthetics\n",
    "- As in Day 2, misfit will be calculated using a waveform misfit. \n",
    "- **Objective**: Determine if we have reduced waveform misfit through model update\n",
    "\n",
    "### a) Setup SPECFEM2D working directory\n",
    "- Let's start out by setting up a new SPECFEM2D working directory where we can manually run the SPECFEM binaries\n",
    "- This task is very similar to Day 2 so we skip over detailed explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f9509-edc4-4f03-9796-b38dfda61c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup block for our SPECFEM2D working directory\n",
    "! mkdir /home/scoped/work/day_3/specfem2d_workdir\n",
    "%cd /home/scoped/work/day_3/specfem2d_workdir\n",
    "\n",
    "# Symlink the binary files located in bin/\n",
    "! ln -s /home/scoped/specfem2d/bin .\n",
    "# Copy over the DATA/ directory with Par_file, SOURCE and STATIONS\n",
    "! cp -r /home/scoped/specfem2d/EXAMPLES/Tape2007/DATA .\n",
    "# Pick a pre-defined Par_file \n",
    "! cp DATA/Par_file_Tape2007_onerec DATA/Par_file\n",
    "# Ensure we are using SOURCE #1\n",
    "! cp DATA/SOURCE_001 DATA/SOURCE\n",
    "# Ensure we are using only STATION #1\n",
    "! head -1 DATA/STATIONS_checker > DATA/STATIONS\n",
    "# Create the output directory\n",
    "! mkdir OUTPUT_FILES\n",
    "\n",
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c4996b-e361-488e-bae5-3a676a603fa9",
   "metadata": {},
   "source": [
    "### Run SPECFEM2D to get model $m_i$ synthetics\n",
    "\n",
    "- First we'll run SPECFEM2D to get model $m_i$ synthetics\n",
    "- We'll later compare these to the updated model ($m_{i+1}$) synthetics\n",
    "- We'll need to adjust some parameter file parameters before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c0c6b-3c82-4c4c-9a31-2e6e76fcaa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell SPECFEM to output binary model files\n",
    "! seisflows sempar -P DATA/Par_file save_model binary\n",
    "! seisflows sempar -P DATA/Par_file setup_with_binary_database 1\n",
    "! seisflows sempar -P DATA/Par_file use_existing_stations .true.\n",
    "\n",
    "# Run SPECFEM with the homogeneous halfspace model, 1 source, 1 station\n",
    "! mpirun -n 1 bin/xmeshfem2D > OUTPUT_FILES/output_mesher.txt\n",
    "! mpirun -n 1 bin/xspecfem2D > OUTPUT_FILES/output_solver.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86436ac3-674f-492f-9a39-d7b73505e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A succesfully completed solver will write data files, expressed in the log\n",
    "! tail -n 30 OUTPUT_FILES/output_solver.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9b52e2-c3a7-4223-8166-c0c5eafb63f3",
   "metadata": {},
   "source": [
    "### Setting the Updated Model as the 'Current' Model\n",
    "\n",
    "- SPECEFM2D needs to be able to find the updated model we just created. \n",
    "- Luckily we can use SeisFlows to write these files in SPECFEM-readable formats.\n",
    "- SPECFEM2D expects model files to be in the DATA/ directory. (**NOTE**: SPECFEM3D expects them to be in the `LOCAL_PATH` directory)\n",
    "- We can OVERWRITE the updated parameters (in this case Vs and Vp) and leave the remainder of the model the same\n",
    "- **IMPORTANT**: The `Par_file` parameter 'MODEL' must be set to `gll`, which tells SPECFEM to read the updated model files we have written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef9a7a-1a81-4be9-8475-689c528d4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we make sure that the original model files are stored somewhere safe\n",
    "! mkdir MODEL_INIT\n",
    "! cp -r DATA/*bin MODEL_INIT\n",
    "! cp -r OUTPUT_FILES/*semd MODEL_INIT\n",
    "\n",
    "print(f\"parameters to be updated are: {m_update.parameters}\")\n",
    "\n",
    "# SeisFlows will overwrite the 'Vp' and 'Vs' binary files\n",
    "m_update.write(path=\"DATA\")\n",
    "\n",
    "# Update the `Par_file` parameter 'MODEL' to tell SPECFEM to read model files from DATA/\n",
    "! seisflows sempar -P DATA/Par_file model gll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343c40c4-302d-4901-b221-4dd0b456d19e",
   "metadata": {},
   "source": [
    "### Run SPECFEM2D with updated model\n",
    "\n",
    "- We can now run `xmeshfem2D` and `xspecfem2D` to retrieve synthetics for our updated model\n",
    "- Since we set `MODEL`==`gll`, SPECFEM2D will know to read the **updated** model files we just wrote\n",
    "- Because we are updating *model* files, we need to **rerun** `xmeshfem2D`\n",
    "- This run will **overwrite** files stored in `OUTPUT_FILES/`. If you want to preserve the original files, you can copy the directory to a new path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f35f69-eeb5-4069-b1b1-10e9825e247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the mesher and solver with the updated velocity model\n",
    "! mpirun -n 1 bin/xmeshfem2D > OUTPUT_FILES/output_mesher_update.txt\n",
    "! mpirun -n 1 bin/xspecfem2D > OUTPUT_FILES/output_solver_update.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ae8578-1bea-44b3-b885-83ba3d90e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can confirm that the updated model was used during the simulation by checking the solver log\n",
    "! head -236 OUTPUT_FILES/output_solver_update.txt | tail -n 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa6bed-6170-433e-a9d6-0a252754bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the final model files are stored somewhere\n",
    "! mkdir MODEL_UPDATE\n",
    "! cp -r DATA/*.bin MODEL_UPDATE\n",
    "! cp -r OUTPUT_FILES/*semd MODEL_UPDATE\n",
    "! ls MODEL_UPDATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114594fc-7de3-412d-b6a4-662fc4865b8b",
   "metadata": {},
   "source": [
    "## 5) Comparing Synthetics for Initial and Updated Models\n",
    "\n",
    "- We now have 2 synthetic seismograms. 1 for the initial model, 1 for the updated model\n",
    "- In a real inversion, we would have 2$\\times$N seismograms, corresonding to N stations \n",
    "- If we plot the two waveforms together we should see that they differ\n",
    "- Our aim is to check both synthetics against the True model synthetics (checkerboard model)\n",
    "- **Objective**: Determine if our updated model has reduced waveform misfit\n",
    "\n",
    "### Compare Initial and Update synthetics\n",
    "\n",
    "- We first want to see if the model update changed the synthetic waveforms\n",
    "- We'll re-use some code snippets from Day 2 to plot synthetics\n",
    "- Initial model synthetics: *red*\n",
    "- Updated model synthetics: *purple*\n",
    "- Initial - Update (waveform difference): *blue*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d5237-f5fa-45b4-b70f-b167fa07f7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_init, d_init = np.loadtxt(\"MODEL_INIT/AA.S000000.BXY.semd\").T\n",
    "t_update, d_update = np.loadtxt(\"MODEL_UPDATE/AA.S000000.BXY.semd\").T\n",
    "\n",
    "# Plot both waveforms using Matplotlib\n",
    "plt.plot(t_init, d_init, c=\"r\", label=\"MODEL INIT; SYNTHETIC\")\n",
    "plt.plot(t_update, d_update, c=\"magenta\", label=\"MODEL UPDATE; 'SYNTHETIC'\")\n",
    "plt.plot(t_init, d_init - d_update, c=\"b\", label=\"SYNTHETIC DIFFERENCE\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Displacement [m]\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c220dca8-3374-460e-a3be-238775eba840",
   "metadata": {},
   "source": [
    "If we zoom into the time window where the two waveforms are different, we can better identify how the model update has affected the synthetic waveforms.\n",
    "The time window of waveform difference (min/max amplitude of the blue wiggle) spans roughly *T0=60s* to *T1=85s*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a1f35-93fc-4e84-a277-9b0b931c4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the same plot as above, but zoom in on time window of waveform difference\n",
    "plt.plot(t_init, d_init, c=\"r\", label=\"MODEL INIT; SYNTHETIC\")\n",
    "plt.plot(t_update, d_update, c=\"magenta\", label=\"MODEL UPDATE; 'SYNTHETIC'\")\n",
    "plt.plot(t_init, d_init - d_update, c=\"b\", label=\"SYNTHETIC DIFFERENCE\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Displacement [m]\")\n",
    "plt.xlim([60, 85])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f0a653-613b-4b7f-bcee-82b834322695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot min/max values to see if model update has affected waveform amplitude\n",
    "print(f\"INITIAL MODEL WAVEFORM: \\n   MIN={d_init.min():.3f}; MAX={d_init.max():.3f}\")\n",
    "print(f\"TARGET MODEL WAVEFORM:  \\n   MIN={d_true.min():.3f}; MAX={d_true.max():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8431d4-db9b-4b4d-b148-93181bfb84da",
   "metadata": {},
   "source": [
    "#### Understanding waveform differences\n",
    "- Visually the waveforms look almost the same. \n",
    "- Zooming in on the time window of waveform difference shows slight waveform differences\n",
    "- The updated synthetics (purple) are slightly *delayed* with respect to the initial model synthetics (red)\n",
    "- Updated synthetics also have slightly larger minimum and maximum amplitudes\n",
    "- Larger model update perturbation (scaling the gradient) would likely have increased the waveform differences seen here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97a08a2-577a-4103-b2cc-1b7ad338724a",
   "metadata": {},
   "source": [
    "### Generating True/Target model synthetics\n",
    "\n",
    "- The final check here is to calculate waveform misfit for the initial and updated models, with respect to the Target checkerboard model.\n",
    "- We will first need to generate checkerboard synthetics, a task that we performed in Day 2\n",
    "- We will also need to re-define our waveform misfit function\n",
    "- **Objective**: Generate True model 'data' and compare against the two synthetic waveforms we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0c8a9-9fb8-4b3c-aca2-79c7c475d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This new par file OVERWRITES the changes we made previously \n",
    "! cp -f DATA/Par_file_Tape2007_132rec_checker DATA/Par_file\n",
    "\n",
    "! seisflows sempar -P DATA/Par_file NSTEP 5000  # 4800 -> 5000 to match the other Par_file\n",
    "! seisflows sempar -P DATA/Par_file save_model binary\n",
    "! seisflows sempar -P DATA/Par_file setup_with_binary_database 1\n",
    "\n",
    "# Ensure that SPECFEM can find the checkerboard model by naming it correctly\n",
    "! cp -f DATA/model_velocity.dat_checker DATA/proc000000_model_velocity.dat_input\n",
    "\n",
    "# Re-run mesher and solver for the Target model\n",
    "! mpirun -n 1 bin/xmeshfem2D > OUTPUT_FILES/output_mesher_true.txt\n",
    "! mpirun -n 1 bin/xspecfem2D > OUTPUT_FILES/output_solver_true.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b39c0a-6b7f-4548-b693-9ec755bfce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store True model binary files and synthetics\n",
    "! mkdir MODEL_TRUE\n",
    "! cp -r DATA/*.bin MODEL_TRUE\n",
    "! cp -r OUTPUT_FILES/*semd MODEL_TRUE\n",
    "! ls MODEL_TRUE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74818a1e-7868-4102-b197-004106071a3d",
   "metadata": {},
   "source": [
    "### Compare Initial, Update synthetics with Target data\n",
    "\n",
    "- We now plot the target model data on top of the waveforms we showed earlier\n",
    "- Target model synthetics (i.e., 'data') was generated using the checkerboard model\n",
    "- Initial model synthetics: *red*\n",
    "- Updated model synthetics: *purple*\n",
    "- Initial - Update (waveform difference): *blue*\n",
    "- Target model synthetics: *black*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f7b1c-393e-4836-912a-99d5174315ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot waveforms with the True model, which will be colored black\n",
    "t_true, d_true = np.loadtxt(\"MODEL_TRUE/AA.S000000.BXY.semd\").T\n",
    "\n",
    "plt.plot(t_init, d_init, c=\"r\", label=\"MODEL INIT; SYNTHETIC\")\n",
    "plt.plot(t_true, d_true, c=\"k\", label=\"MODEL TRUE; 'DATA'\")\n",
    "plt.plot(t_update, d_update, c=\"magenta\", label=\"MODEL UPDATE; 'SYNTHETIC'\")\n",
    "plt.plot(t_init, d_init - d_update, c=\"b\", label=\"SYNTHETIC DIFFERENCE\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Displacement [m]\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff13dd-1c85-4d6b-9f3a-bc44d4e2feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a zoom on the waveform difference time window\n",
    "plt.plot(t_init, d_init, c=\"r\", label=\"MODEL INIT; SYNTHETIC\")\n",
    "plt.plot(t_true, d_true, c=\"k\", label=\"MODEL TRUE; 'DATA'\")\n",
    "plt.plot(t_update, d_update, c=\"magenta\", label=\"MODEL UPDATE; 'SYNTHETIC'\")\n",
    "plt.plot(t_init, d_init - d_update, c=\"b\", label=\"SYNTHETIC DIFFERENCE\")\n",
    "plt.xlim([60, 85])\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Displacement [m]\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b76408-b0f5-4c2c-a62d-be4eab88f732",
   "metadata": {},
   "source": [
    "#### Understanding waveform differences\n",
    "- Target model synthetics (black) are *delayed* compared to initial model synthetics (red), by approximately 3s\n",
    "- Target model synthetics (black) show *larger* amplitudes compared to initial model synthetics (red)\n",
    "- By visual inspection, the updated model synthetics (purple) appear to be moving *towards* the target synthetics (black)\n",
    "- Visual inspection is a qualitative measure, we would rather **quantify** waveform misfit to determine if the updated synthetics better fit target synthetics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0107ee31-b38d-452d-be69-fcee7a354e3e",
   "metadata": {},
   "source": [
    "### Quantfiying Waveform Misfit\n",
    "\n",
    "- As in Day 2 we will calculate a waveform misfit $\\chi$, whose equation is: $ \\chi = \\frac{1}{2} \\int [d(t)-s(t)]^2 dt~$\n",
    "- In the equation above, $d(t)$ represents 'data' and $s(t)$ represents 'synthetics'\n",
    "- We want to compare data with both the True model and the updated model, so we need to calculate $\\chi$ twice\n",
    "- **Objective**: Determine if the model update has reduced waveform misfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac696a3a-0b3a-4ec0-b732-b4608d0f77a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrate using scipy\n",
    "dt = t_true[1] - t_true[0]  # represents the time step, or `dt`. Same for all waveforms\n",
    "\n",
    "# Use simpsons rule for integration\n",
    "misfit_init = 1/2 * simps((d_true - d_init)**2, dx=dt)\n",
    "misfit_update = 1/2 * simps((d_true - d_update)**2, dx=dt)\n",
    "\n",
    "print(f\"misfit_init = {misfit_init:.3E}\")\n",
    "print(f\"misfit_true = {misfit_update:.3E}\")\n",
    "print(f\"init - true = {misfit_init - misfit_update:.3E}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898115dc-70ca-4a30-97e3-68ae1f5327c0",
   "metadata": {},
   "source": [
    "---------------\n",
    "\n",
    "**Mission accomplished!**\n",
    "- We have successfully reduced the waveform misfit for a single source receiver pair by updating our velocity model.\n",
    "- The misfit reduction is relatively small; it is tied to the gradient and chosen scale factor\n",
    "- We could increase the scale factor to achieve a more favorable misfit reduction, however if we go too far, we may end up increasing the misfit.\n",
    "- Algorithmically, this step is defined in a `line search`, which attempts to find an appropriate scale factor for model update\n",
    "- There are many types of nonlinear optimization algorithms (e.g., gradient descent, L-BFGS) which are used to determine scale factors in an effort to minimize misfit\n",
    "- **NOTE** each evaluation of a line search requires **re-running** the forward simulation with a trial model, it is therefore ideal to find the best performing algorithm to keep computational costs down \n",
    "- See e.g., [Modrak and Tromp (2016)](https://academic.oup.com/gji/article/206/3/1864/2583505) for exploration of how various algorithms perform in the context of seismic inverison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ab8b9f-e443-4f8b-8372-acf7152ee29a",
   "metadata": {},
   "source": [
    "## 6) A Multi-event, Multi-station Inversion\n",
    "\n",
    "- Real seismic inversions use multiple events recorded at multiple stations to increase coverage and reduce nonuniqueness\n",
    "- Here we attempt a *multi-event* ($N=10$), multi-station ($S=10$) model update with the tools we just covered\n",
    "- We forgo visualizations and detailed explanations for the sake of brevity\n",
    "- The inversion workflow is the same as above: \n",
    "    0) **data**: run $N$ forward simulations to generate *data* using target model ($m_{true}$) for $N$ events and $S$ stations\n",
    "    1) **synthetics**: run $N$ forward simulations to generate synthetics through starting model ($m_{init}$) for $N$ events and $S$ stations\n",
    "    2) **misfit**: quantify data-synthetic misfit ($\\chi_{init}$) and generate adjoint sources for each source-receiver pair ($N\\times S$ waveforms)\n",
    "    3) **kernels**: generate misfit kernels with $N$ adjoint simulation\n",
    "    4) **update**: scale gradient and update initial model to get trial model: $m_{try}$\n",
    "    5) **line search**: run $N$ forward simulations using trial model $m_{try}$ to get $N \\times S$ new synthetic waveforms\n",
    "    6) **line search**: calculate misfit ($\\chi_{try}$) and determine if misfit is reduced ($\\chi_{try} < \\chi_{init}$?)\n",
    "    7) **line search**: if misfit is not reduced ($\\chi_{try} >=  \\chi_{init}$), repeat steps 5-7 with newly scaled gradient\n",
    "    8) **line search**: if misfit is reduced, accept trial model as newly updated model ($m_{try} \\rightarrow m_{01}$)\n",
    "    9) **finalize**: set newly updated model as initial model ($m_{01} \\rightarrow m_{init}$) and repeat steps 1-9\n",
    "    \n",
    "    \n",
    "Much of this experimental setup was shown in Day 2 but in Section (a) we will plot the sources and stations to be used here to provide some context to the inversion problem that will be run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f632f2d-a754-4b1b-88fc-84677e958b98",
   "metadata": {},
   "source": [
    "### a) Generating 100 Target Model Synthetics\n",
    "\n",
    "- Checkerboard model used to generate 'data'\n",
    "- Homogeneous halfspace model as our 'initial' model to generate synthetics\n",
    "- 10 sources and 10 stations with pre-defined locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b28770-0cf8-40c3-af6d-d55049b3db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we're in an empty working directory\n",
    "! mkdir -p /home/scoped/work/day_3/inversion_example\n",
    "%cd /home/scoped/work/day_3/inversion_example\n",
    "\n",
    "# Setup SPECFEM2D working directory\n",
    "! ln -s /home/scoped/specfem2d/bin .\n",
    "! cp -r /home/scoped/specfem2d/EXAMPLES/Tape2007/DATA .\n",
    "! cp -f DATA/Par_file_Tape2007_132rec_checker DATA/Par_file\n",
    "! seisflows sempar -P DATA/Par_file save_model binary\n",
    "! seisflows sempar -P DATA/Par_file setup_with_binary_database 1\n",
    "! seisflows sempar -P DATA/Par_file use_existing_stations .true.\n",
    "! head -10 DATA/STATIONS_checker > DATA/STATIONS  # 10 stations\n",
    "! mkdir OUTPUT_FILES\n",
    "\n",
    "# This new par file OVERWRITES the changes we made previously \n",
    "! seisflows sempar -P DATA/Par_file NSTEP 5000  # 4800 -> 5000 to match the other Par_file\n",
    "! seisflows sempar -P DATA/Par_file save_model binary\n",
    "! seisflows sempar -P DATA/Par_file setup_with_binary_database 1\n",
    "\n",
    "# Ensure that SPECFEM can find the checkerboard model by naming it correctly\n",
    "! cp -f DATA/model_velocity.dat_checker DATA/proc000000_model_velocity.dat_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2057bb78-a098-4bea-a71d-85298c861932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small code block to plot source-receiver geometry with text labels\n",
    "# Grab station locations\n",
    "sta_x, sta_z = np.genfromtxt(\"DATA/STATIONS\", dtype=float, usecols=[2, 3]).T\n",
    "# Grab event locations\n",
    "ev_x, ev_z = [], []\n",
    "for i in range(1, 11):\n",
    "    source_file = f\"DATA/SOURCE_{i:0>3}\"\n",
    "    with open(source_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    # Trying to break apart the following line\n",
    "    # 'xs = 299367.72      # source location x in meters\\n'\n",
    "    xs = float(lines[2].split(\"=\")[1].split(\"#\")[0].strip())\n",
    "    zs = float(lines[3].split(\"=\")[1].split(\"#\")[0].strip())\n",
    "    \n",
    "    ev_x.append(xs)\n",
    "    ev_z.append(zs)\n",
    "# Plot SOURCES and STATIONS geometry\n",
    "for i, (x, z) in enumerate(zip(ev_x, ev_z)):\n",
    "    plt.scatter(x, z, c=\"y\", marker=\"*\", edgecolor=\"k\", s=50)\n",
    "    plt.text(x, z, f\"S{i+1:0>2}\", fontsize=9, c=\"r\")  # SOURCE numbering starts at 1\n",
    "for i, (x, z) in enumerate(zip(sta_x, sta_z)):\n",
    "    plt.scatter(x, z, c=\"c\", marker=\"v\", s=40, edgecolor=\"k\")\n",
    "    plt.text(x, z, f\"R{i:0>2}\", fontsize=9)\n",
    "# Finalize plot labels\n",
    "plt.xlabel(\"X [m]\")\n",
    "plt.ylabel(\"Z [m]\")\n",
    "plt.xlim([0, 480E3])\n",
    "plt.ylim([0, 480E3])\n",
    "plt.title(\"SOURCE-RECEIVER GEOMETRY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec037c1-ac46-41ab-9c0e-6c831c5e017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a re-usable function because we will be running a lot of forward simulations\n",
    "def run_fwd_mesher_solver(ntask, save_synthetics, save_forward=False):\n",
    "    \"\"\"\n",
    "    Run the mesher and solver `ntask` times. Save the resulting synthetics\n",
    "    to path `save_synthetics`\n",
    "    \n",
    "    :type ntask: int\n",
    "    :param ntask: number of sources to run\n",
    "    :type save_synthetics: str\n",
    "    :param save_synthetics: relative directory name to save synthetics to\n",
    "    \"\"\"\n",
    "    print(f\"Generating synthetics for {ntask} sources\")\n",
    "    # Run 10 forward simulations using Target model, generating 'data' for 10 stations. \n",
    "    for i in range(1, ntask + 1):\n",
    "        # Choose the task/source to run mesher/sovler with\n",
    "        source_fid = f\"SOURCE_{i:0>3}\"\n",
    "        print(f\"Running mesher and solver for {source_fid}\")\n",
    "        source_path = f\"DATA/{source_fid}\"\n",
    "\n",
    "        # Set the correct source for SPECFEM to find\n",
    "        if os.path.exists(\"DATA/SOURCE\"):\n",
    "            os.remove(\"DATA/SOURCE\")\n",
    "        shutil.copy(source_path, \"DATA/SOURCE\")\n",
    "\n",
    "        # Run xmeshfem and xspecfem. \n",
    "        # Note: We actually only have to run the mesher once to set up the database files, \n",
    "        #     but it's cheap so we do it for each source. In 3D you may want to skip that step.\n",
    "        ! mpirun -n 1 bin/xmeshfem2D > OUTPUT_FILES/output_mesher.txt\n",
    "        ! mpirun -n 1 bin/xspecfem2D > OUTPUT_FILES/output_solver.txt\n",
    "\n",
    "        # Move the just-generated synthetic waveforms so they don't get overwritten\n",
    "        os.makedirs(os.path.join(source_fid, save_synthetics))\n",
    "        for src in glob(\"OUTPUT_FILES/*.semd\"):\n",
    "            dst = os.path.join(source_fid, save_synthetics, os.path.basename(src))\n",
    "            os.rename(src, dst)\n",
    "        \n",
    "        # Save forward arrays stored on disk if available\n",
    "        if save_forward:\n",
    "            print(f\"saving forward arrays {source_fid}\")\n",
    "            save_fwd_dir = os.path.join(source_fid, \"SAVE_FORWARD\")\n",
    "            if not os.path.exists(save_fwd_dir):\n",
    "                os.makedirs(save_fwd_dir)\n",
    "            # Save fwd arrays are the last frame and boundary conditions\n",
    "            fid_templates = [\"lastframe_elastic*.bin\", \"absorb_elastic_*.bin\"]\n",
    "            for fid in fid_templates:\n",
    "                for src in glob(f\"OUTPUT_FILES/{fid}\"):\n",
    "                    dst = os.path.join(save_fwd_dir, os.path.basename(src))\n",
    "                    os.rename(src, dst)\n",
    "        \n",
    "    print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c4bd1-baba-4270-9965-ce4937bb0e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the mesher and solver for the Initial model and 10 sources.\n",
    "run_fwd_mesher_solver(ntask=10, save_synthetics=\"TARGET_DATA\", save_forward=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b25d57-4d98-4594-972a-fab2afe47f6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### b) Generating 100 Initial Model Synthetics\n",
    "\n",
    "- Now we generate synthetics through out homogeneous halfspace initial model\n",
    "- We will **also** need the forward wavefield (output from `SAVE_FORWARD`) from the forward simulation of each $N$ events.\n",
    "- The saved forward wavefield is a snapshot of the forward wavefield at the last time step, used to back-reconstruct the forward wavefield\n",
    "- The saved forward wavefield is required to run each of the $N$ subsquent adjoint simulations\n",
    "- For large domains (and especially in 3D), saved forward wavefields are **large** files (on the order of GB)\n",
    "- It is *not* preferable to save these large files permanently. Ideally we would calculate misfit, run adjoint simulations, and then remove the forward wavefield\n",
    "- We will follow that practice here by deleting the forward wavefield after each adjoint simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b1500-f7b0-471e-b29d-7a780e2a0488",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/scoped/work/day_3/inversion_example\n",
    "\n",
    "# Re-set the SPECFEM2D Par_file which is set up for the Initial model\n",
    "! cp -f DATA/Par_file_Tape2007_onerec DATA/Par_file\n",
    "\n",
    "# Edit Par_file to get the correct output files for Initial model\n",
    "! seisflows sempar -P DATA/Par_file save_model binary\n",
    "! seisflows sempar -P DATA/Par_file setup_with_binary_database 1\n",
    "! seisflows sempar -P DATA/Par_file use_existing_stations .true.\n",
    "! seisflows sempar -P DATA/Par_file save_forward .true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f9e9c-10cf-49a3-9095-9d7497968fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run mesher and solver for the Target model and 10 sources. Save forward arrays for subsequent adjoint simulations\n",
    "run_fwd_mesher_solver(ntask=10, save_synthetics=\"SYNTHETICS\", save_forward=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63eb49-79af-4df0-9b4f-2e04c712981e",
   "metadata": {},
   "source": [
    "### c) Quantifying misfit and generating adjoint sources\n",
    "\n",
    "- Now  we need to quantify misfit for all $N \\times S$ waveforms\n",
    "- We also need to generate $N \\times S$ adjoint sources for subsequent adjoint simulations\n",
    "- We'll use a waveform difference misfit for simplicity: $ \\chi = \\frac{1}{2} \\int [d(t)-s(t)]^2 dt~$\n",
    "- The corresponding waveform difference adjoint source: $f^\\dagger (t) = s(t) - d(t)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589656b4-b9c9-43cf-a8ff-2c5c6bf33eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we define a function that will calculate misfit and generate adjoint sources\n",
    "def quantify_misfit(data_fid, syn_fid): \n",
    "    \"\"\"\n",
    "    Quantify misfit and generate adjoint source\n",
    "    \n",
    "    :type data_fid: str\n",
    "    :param data_fid: filename and path to data array\n",
    "    :type syn_fid: str\n",
    "    :param syn_fid: filename and path to synthetic array\n",
    "    \"\"\"\n",
    "    t_data, d_data = np.loadtxt(data_fid).T\n",
    "    t_syn, d_syn = np.loadtxt(syn_fid).T\n",
    "    dt = t_syn[1] - t_syn[0]  # dt represents the time step\n",
    "    \n",
    "    # Calculate waveform difference misfit\n",
    "    misfit = 1/2 * simps((d_data - d_syn)**2, dx=dt)\n",
    "    \n",
    "    # Create the time-amplitude array for adjoint source\n",
    "    d_adj = d_init - d_true\n",
    "    adj_src = np.vstack((t_syn, d_adj)).T\n",
    "    \n",
    "    return misfit, adj_src    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f744fde-c31e-4c23-8efe-f72bb813c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this code block we quantify misfit and store results accordingly\n",
    "for src in sorted(glob(\"SOURCE_???\")):\n",
    "    print(f\"Quantifying misfit for {src}\")\n",
    "    \n",
    "    # Set up directories to store misfit and adjoint sources\n",
    "    adj_src_dir = os.path.join(src, \"ADJOINT_SOURCE\")\n",
    "    misfit_file = os.path.join(src, \"MISFIT.txt\")\n",
    "    \n",
    "    if not os.path.exists(adj_src_dir):\n",
    "        os.makedirs(os.path.join(src, \"ADJOINT_SOURCE\"))\n",
    "        \n",
    "    if os.path.exists(misfit_file):\n",
    "        os.remove(misfit_file)\n",
    "\n",
    "    # Loop through each of the syntheitc waveforms\n",
    "    for syn_fid in sorted(glob(os.path.join(src, \"SYNTHETICS\", \"*\"))):\n",
    "        # e.g., AA.S000001.BXY.semd\n",
    "        fid_base = os.path.basename(syn_fid)\n",
    "        \n",
    "        print(f\"\\t{fid_base}\", end=\"; \")\n",
    "        data_fid = os.path.join(src, \"TARGET_DATA\", fid_base)\n",
    "        \n",
    "        # Calculate the misfit and generate adjoint source    \n",
    "        misfit, adj_src = quantify_misfit(data_fid, syn_fid)\n",
    "        \n",
    "        # Write misfit to file\n",
    "        print(f\"MISFIT={misfit:.3E}\")\n",
    "        with open(misfit_file, \"a\") as f:\n",
    "            f.write(f\"{misfit}\\n\")\n",
    "        \n",
    "        # Write adjoint source to file\n",
    "        # Note that SPECFEM expects adjoint sources to be suffixed '.adj.\n",
    "        np.savetxt(os.path.join(adj_src_dir, fid_base.replace(\"semd\", \"adj\")), adj_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a85d25-85a3-4719-93e6-8c09da4ee6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can take a look at the files we just created\n",
    "! ls SOURCE_001\n",
    "! echo \n",
    "! echo \"> ADJOINT SOURCES\"\n",
    "! ls SOURCE_001/ADJOINT_SOURCE\n",
    "! echo \n",
    "! echo \"> SOURCE_001/ADJOINT_SOURCE/AA.S000000.BXY.adj\"\n",
    "! head SOURCE_001/ADJOINT_SOURCE/AA.S000000.BXY.adj\n",
    "! echo\n",
    "! echo \"> SOURCE_001/MISFIT.txt\"\n",
    "! head SOURCE_001/MISFIT.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f2a77-b0e5-4531-b260-5080781e6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an example of data, synthetic and adjoint source\n",
    "t_init, d_init = np.loadtxt(\"SOURCE_001/SYNTHETICS/AA.S000000.BXY.semd\").T\n",
    "t_true, d_true = np.loadtxt(\"SOURCE_001/TARGET_DATA/AA.S000000.BXY.semd\").T\n",
    "t_adjs, d_adjs = np.loadtxt(\"SOURCE_001/ADJOINT_SOURCE/AA.S000000.BXY.adj\").T\n",
    "\n",
    "plt.plot(t_init, d_init, c=\"r\", label=\"SYNTHETIC\")\n",
    "plt.plot(t_true, d_true, c=\"k\", label=\"'DATA'\")\n",
    "plt.plot(t_adjs, d_adjs, c=\"g\", label=\"ADJOINT SOURCE\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Displacement [m]\")\n",
    "plt.title(\"DATA-SYNTHETIC COMPARISON\\nSOURCE 001; AA.S000000.BXY\")\n",
    "plt.xlim([25, 150])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc8b33-6d69-4e81-a51c-e82148ad75b1",
   "metadata": {},
   "source": [
    "#### Understanding misfit quantification\n",
    "- For each of our $N$ sources we have quantified misfit for $S$ stations\n",
    "- Each synthetic has a corresponding adjoint source, which is stored in `SOURCE_???/ADJOINT_SOURCE`\n",
    "- Each adjoint source is equal to the waveform difference between data and synthetic\n",
    "- Each adjoint source has a corresponding misfit value\n",
    "- Misfit values are stored in a text file which can be summed to calculate the overall **event misfit**\n",
    "- The adjoint sources will be used to run $N$ adjoint simulations\n",
    "- The misfit value will be used to determine if misfit is reduced during the line search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2990d06-1b94-4524-890f-925745db5688",
   "metadata": {},
   "source": [
    "### d) Running $N$ adjoint simulations to generate event kernels\n",
    "\n",
    "- Now we need to run the adjoint simulations to generate event kernels\n",
    "- Event kernels tell us what parts of the model are sensitive to the misfit function for **EACH** event\n",
    "- Adjoint simulations take $S$ adjoint sources as input \n",
    "- **NOTE**: We need to place the adjoint sources in the correct location and also tell SPECFEM that we are running an adjoint simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee116fa-5019-4984-b78f-606a676beb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_adj_solver(ntask):\n",
    "    \"\"\"\n",
    "    Counterpart to `run_fwd_mesher_solver`, runs adjoint simulations for `ntask` events\n",
    "    and saves the resulting kernels\n",
    "    \"\"\"\n",
    "    for i in range(1, ntask + 1):\n",
    "        # Choose the task/source to run mesher/sovler with\n",
    "        source_fid = f\"SOURCE_{i:0>3}\"\n",
    "        assert(os.path.exists(source_fid)), f\"no corresponding fwd results for {source_fid}\"\n",
    "        \n",
    "        print(f\"Running adjoint simulation for {source_fid}\")\n",
    "        source_path = f\"DATA/{source_fid}\"\n",
    "\n",
    "        # Set the correct source for SPECFEM to find\n",
    "        if os.path.exists(\"DATA/SOURCE\"):\n",
    "            os.remove(\"DATA/SOURCE\")\n",
    "        shutil.copy(source_path, \"DATA/SOURCE\")\n",
    "                \n",
    "        # Symlink adjoint sources so SPECFEM can find them\n",
    "        if os.path.exists(\"SEM\"):\n",
    "            os.remove(\"SEM\")\n",
    "        os.symlink(os.path.join(source_fid, \"ADJOINT_SOURCE\"), \"SEM\")\n",
    "        \n",
    "        # Copy the saved forward array so that SPECFEM can use it\n",
    "        for src in glob(os.path.join(source_fid, \"SAVE_FORWARD\", \"*\")):\n",
    "            dst = os.path.join(\"OUTPUT_FILES\", os.path.basename(src))\n",
    "            if os.path.exists(dst):\n",
    "                os.remove(dst)\n",
    "            shutil.copy(src, dst)\n",
    "            \n",
    "        # Run the adjoint simulation\n",
    "        ! mpirun -n 1 bin/xspecfem2D > OUTPUT_FILES/adjoint_solver.txt\n",
    "        \n",
    "        # # Move the resulting kernel outputs to disk\n",
    "        kernel_dir = os.path.join(source_fid, \"KERNELS\")\n",
    "        os.makedirs(kernel_dir)\n",
    "        for src in glob(\"OUTPUT_FILES/*kernel.bin\"):\n",
    "            dst = os.path.join(kernel_dir, os.path.basename(src))\n",
    "            os.rename(src, dst)\n",
    "            \n",
    "        print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee16e72-3d2e-48b2-a7f5-f9f5e4f5813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Par_file to run an adjoint simulation and output kernels in expected output\n",
    "! seisflows sempar -P DATA/Par_file simulation_type 3\n",
    "! seisflows sempar -P DATA/Par_file save_ASCII_kernels .false.\n",
    "\n",
    "# Run adjoint simluation for each N sources\n",
    "run_adj_solver(ntask=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af05d6e0-7607-453a-a681-2b78f44633b7",
   "metadata": {},
   "source": [
    "### e) Summing kernels and scaling gradient\n",
    "\n",
    "- Now we have $N$=10 event kernels, each representing misfit sensitivity for each of the $N$ events\n",
    "- We need to sum the event kernels into a misfit kernel, which represents misfit sensitivity for **all** $N$ events\n",
    "- We can use the `xcombine_sem` executable to sum these kernels\n",
    "- Before perturbing the initial model, we need to *scale* the misfit kernel \n",
    "- The scaled misfit kernel is the gradient, which we can use to perturb the initial model\n",
    "- The call structure for `xcombine_sem` is:  *mpirun -n NPROC bin/xcombine_sem KERNEL_NAMES INPUT_FILE OUTPUT_DIR*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823aa354-b454-4595-8e9a-a114fbeb19ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this block we sum event kernels into a misfit kernel\n",
    "# First we need to tell SPECFEM where all our kernel files are\n",
    "with open(\"kernel_paths.txt\", \"w\") as f:\n",
    "    for fid in sorted(glob(\"SOURCE_???/KERNELS\")):\n",
    "        f.write(f\"{os.path.abspath(fid)}\\n\")\n",
    "\n",
    "# Make a directory to store these files\n",
    "! mkdir GRADIENT\n",
    "\n",
    "# Then we run `xcombine_sem` to combine kernels for various kernel names\n",
    "! mpirun -n 1 bin/xcombine_sem alpha_kernel,beta_kernel kernel_paths.txt GRADIENT \n",
    "\n",
    "# Rename 'alpha' to Vp and 'beta' to Vs for easier name recognition\n",
    "for src in glob(\"GRADIENT/*\"):\n",
    "    if \"alpha\" in src:\n",
    "        os.rename(src, src.replace(\"alpha\", \"vp\"))\n",
    "    elif \"beta\" in src:\n",
    "        os.rename(src, src.replace(\"beta\", \"vs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2154d-4487-4de3-8188-0bc7834d60ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell we'll scale the gradient (Vp and Vs only) by GTG^-1\n",
    "vp_kernel = read_fortran_binary(\"GRADIENT/proc000000_vp_kernel.bin\")\n",
    "vs_kernel = read_fortran_binary(\"GRADIENT/proc000000_vs_kernel.bin\")\n",
    "\n",
    "# The gradient starts out as a vector of kernels for all parameters\n",
    "gradient = np.hstack((vp_kernel, vs_kernel))\n",
    "\n",
    "# Caclulating GTG^-1\n",
    "gtg = np.dot(gradient, gradient)\n",
    "gtg_inverse = gtg ** -1 \n",
    "\n",
    "print(f\"GTG^-1 = {gtg_inverse:.2f}\")\n",
    "\n",
    "# Scaling the gradient by GTG^-1\n",
    "gradient = gradient * gtg_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e526682-2ee6-4deb-a1c7-827be9a04b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the gradient\n",
    "x = read_fortran_binary(\"DATA/proc000000_x.bin\")\n",
    "z = read_fortran_binary(\"DATA/proc000000_z.bin\")\n",
    "n = len(gradient) // 2\n",
    "g_vp = gradient[:n]\n",
    "g_vs = gradient[n:]\n",
    "\n",
    "plt.tricontourf(x, z, g_vs, levels=125, cmap=\"RdYlGn\")\n",
    "plt.colorbar()\n",
    "\n",
    "# Plot SOURCES and STATIONS geometry\n",
    "for i, (x, z) in enumerate(zip(ev_x, ev_z)):\n",
    "    plt.scatter(x, z, c=\"y\", marker=\"*\", edgecolor=\"k\", s=50)\n",
    "    plt.text(x, z, f\"S{i+1:0>2}\", fontsize=9, c=\"r\")  # SOURCE numbering starts at 1\n",
    "for i, (x, z) in enumerate(zip(sta_x, sta_z)):\n",
    "    plt.scatter(x, z, c=\"c\", marker=\"v\", s=40, edgecolor=\"k\")\n",
    "    plt.text(x, z, f\"R{i:0>2}\", fontsize=9)\n",
    "\n",
    "plt.xlabel(\"X [m]\")\n",
    "plt.ylabel(\"Z [m]\")\n",
    "plt.title(\"Gradient Vs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e6be4-b9f4-4d85-9d23-61e67fea378f",
   "metadata": {},
   "source": [
    "!!! DISCUSS THIS FIGURE !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b54ad08-0b1d-49d4-95d7-d8924d8c578f",
   "metadata": {},
   "source": [
    "### f) Smoothing the gradient\n",
    "\n",
    "- The gradient above shows a lot of small scale heterogeneity\n",
    "- This may be due to the summation of $N$=10 event kernels\n",
    "- We can use regularization to smooth out the gradient to get a more conservative picture of model update\n",
    "- We use the `xsmooth_sem` executable to smooth our kernels\n",
    "\n",
    " The usage of `xsmooth_sem` is given as\n",
    " ```bash\n",
    " USAGE:  mpirun -np NPROC bin/xsmooth_sem SIGMA_H SIGMA_V KERNEL_NAME INPUT_DIR OUPUT_DIR GPU_MODE\n",
    " ```\n",
    " We will need to choose values and directories to make this work\n",
    "  - `SIGMA_H`: Horizontal smoothing length [m] representing the horizontal half-width of the Gaussian  \n",
    "  - `SIGMA_Z`: Vertical smoothing length [m] representing the vertical half-width of the Gaussian  \n",
    "  - `KERNEL_NAME`: The name of the kernel we want to smooth. Must match filename, so `proc000000_vs_kernel.bin` will correspond to kernel name `vs_kernel`  \n",
    "  - `INPUT_DIR`: where SPECFEM can find the kernel files\n",
    "  - `OUTPUT_DIR`: Where SPECFEM should output the SMOOTHED kernels \n",
    "  - `GPU_MODE`: Use GPU acceleration to speed up the smoothing operation (.true. or .false.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce8b829-3bd6-4b80-99db-332d9c0e8ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECFEM Requires that some of the model files be discoverable alongside the kernels\n",
    "! cp -f GRADIENT/*.bin DATA/\n",
    "! mpirun -n 1 bin/xsmooth_sem 25000 25000 vs_kernel DATA/ GRADIENT/ .false.\n",
    "! mpirun -n 1 bin/xsmooth_sem 25000 25000 vp_kernel DATA/ GRADIENT/ .false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aefc2d8-6e52-4c38-9151-a73c2ae05255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the smoothed gradient\n",
    "x = read_fortran_binary(\"DATA/proc000000_x.bin\")\n",
    "z = read_fortran_binary(\"DATA/proc000000_z.bin\")\n",
    "vp_kernel = read_fortran_binary(\"GRADIENT/proc000000_vp_kernel_smooth.bin\")\n",
    "vs_kernel = read_fortran_binary(\"GRADIENT/proc000000_vs_kernel_smooth.bin\")\n",
    "\n",
    "# The gradient starts out as a vector of kernels for all parameters\n",
    "gradient = np.hstack((vp_kernel, vs_kernel))\n",
    "\n",
    "# Caclulating GTG^-1\n",
    "gtg = np.dot(gradient, gradient)\n",
    "gtg_inverse = gtg ** -1 \n",
    "\n",
    "print(f\"GTG^-1 = {gtg_inverse:.2f}\")\n",
    "\n",
    "# Scaling the gradient by GTG^-1\n",
    "gradient = gradient * gtg_inverse\n",
    "\n",
    "n = len(gradient) // 2\n",
    "g_vp = gradient[:n]\n",
    "g_vs = gradient[n:]\n",
    "\n",
    "plt.tricontourf(x, z, g_vs, levels=125, cmap=\"RdYlGn\")\n",
    "plt.colorbar()\n",
    "\n",
    "# Plot SOURCES and STATIONS geometry\n",
    "for i, (x, z) in enumerate(zip(ev_x, ev_z)):\n",
    "    plt.scatter(x, z, c=\"y\", marker=\"*\", edgecolor=\"k\", s=50)\n",
    "    plt.text(x, z, f\"S{i+1:0>2}\", fontsize=9, c=\"r\")  # SOURCE numbering starts at 1\n",
    "for i, (x, z) in enumerate(zip(sta_x, sta_z)):\n",
    "    plt.scatter(x, z, c=\"c\", marker=\"v\", s=40, edgecolor=\"k\")\n",
    "    plt.text(x, z, f\"R{i:0>2}\", fontsize=9)\n",
    "    \n",
    "# Connect sources and receivers with lines\n",
    "for (ex, ez) in zip(ev_x, ev_z):\n",
    "    for (sx, sz) in zip(sta_x, sta_z):\n",
    "        plt.plot((ex, sx), (ez, sz), c=\"k\", lw=.25)\n",
    "\n",
    "\n",
    "plt.xlabel(\"X [m]\")\n",
    "plt.ylabel(\"Z [m]\")\n",
    "plt.title(\"Gradient Vs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f125870-b51d-4c6f-948b-b43d2eac9ce5",
   "metadata": {},
   "source": [
    "### g) Perturbing the initial model\n",
    "\n",
    "- We can perturb the initial model with the gradient to generate an update model ($m_{try}$)\n",
    "- We'll use this updated model to run forward simulations\n",
    "- Quantifying misfit of these new synthetics, we can determine if our misfit is reduced\n",
    "- Successful reduction of misfit equals a successful line search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e53b3-1fb4-415a-b3fc-1a1b3a14a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! MOVE THIS TO \n",
    "# First we store the starting model incase we need it again\n",
    "! mkdir MODEL_INIT\n",
    "! mkdir MODEL_01\n",
    "\n",
    "# These files define a SPECFEM2D model\n",
    "for tag in [\"x\", \"z\", \"rho\", \"vp\", \"vs\", \"NSPEC_ibool\", \"jacobian\"]:\n",
    "    src = f\"DATA/proc000000_{tag}.bin\"\n",
    "    # Copy to initial model directory\n",
    "    dst = f\"MODEL_INIT/{os.path.basename(src)}\"\n",
    "    shutil.copy(src, dst)\n",
    "    # Copy to Model 01 directory, we will overload some of these\n",
    "    dst = f\"MODEL_01/{os.path.basename(src)}\"\n",
    "    shutil.copy(src, dst)\n",
    "    \n",
    "# Now we load the initial model velocity so we can overload them\n",
    "vp = read_fortran_binary(\"MODEL_01/proc000000_vp.bin\")\n",
    "vs = read_fortran_binary(\"MODEL_01/proc000000_vs.bin\")\n",
    "\n",
    "# Perturb the initial model by the gradient\n",
    "vp += g_vp\n",
    "vs += g_vs\n",
    "\n",
    "# Over write Vp and Vs for Model 01 with perturbed model\n",
    "write_fortran_binary(vp, \"MODEL_01/proc000000_vp.bin\")\n",
    "write_fortran_binary(vs, \"MODEL_01/proc000000_vs.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e07abdc-e9e5-4b51-ab88-6f99c96490e5",
   "metadata": {},
   "source": [
    "### g) Run forward simulations with M01, quantify misfit\n",
    "\n",
    "- Now that we have a perturbed model (Model 01; M01) we can use it to run forward simulations\n",
    "- We can calculate misfit for each of the new synthetics\n",
    "- We can compare the overall misfit of the initial model to Model 01\n",
    "- **Objective**: determine if we have reduced waveform misfit through our model perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa3506-55c3-4695-8d8c-f8260cc103d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the correct velocity model where SPECFEM expects it\n",
    "for tag in [\"x\", \"z\", \"rho\", \"vp\", \"vs\", \"NSPEC_ibool\", \"jacobian\"]:\n",
    "    src = f\"MODEL_01/proc000000_{tag}.bin\"\n",
    "    dst = f\"DATA/proc000000_{tag}.bin\"\n",
    "    if os.path.exists(dst):\n",
    "        os.remove(dst)\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "# Reset the simulation type to forward\n",
    "! seisflows sempar -P DATA/Par_file simulation_type 1\n",
    "! seisflows sempar -P DATA/Par_file model gll\n",
    "\n",
    "run_fwd_mesher_solver(ntask=10, save_synthetics=\"SYNTHETICS_01\", save_forward=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af40acf-198b-4a8a-9ae7-9e0f9942b94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this code block we quantify misfit and store results accordingly\n",
    "for src in sorted(glob(\"SOURCE_???\")):\n",
    "    print(f\"Quantifying misfit for {src}\")\n",
    "    \n",
    "    # Set up directories to store misfit and adjoint sources\n",
    "    misfit_file = os.path.join(src, \"MISFIT_01.txt\")\n",
    "\n",
    "    if os.path.exists(misfit_file):\n",
    "        os.remove(misfit_file)\n",
    "\n",
    "    # Loop through each of the syntheitc waveforms\n",
    "    for syn_fid in sorted(glob(os.path.join(src, \"SYNTHETICS_01\", \"*\"))):\n",
    "        # e.g., AA.S000001.BXY.semd\n",
    "        fid_base = os.path.basename(syn_fid)\n",
    "        \n",
    "        print(f\"\\t{fid_base}\", end=\"; \")\n",
    "        data_fid = os.path.join(src, \"TARGET_DATA\", fid_base)\n",
    "        \n",
    "        # Calculate the misfit and generate adjoint source    \n",
    "        misfit, adj_src = quantify_misfit(data_fid, syn_fid)\n",
    "        \n",
    "        # Write misfit to file\n",
    "        print(f\"MISFIT={misfit:.3E}\")\n",
    "        with open(misfit_file, \"a\") as f:\n",
    "            f.write(f\"{misfit}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63f68d1-0c03-4e2d-827a-1f441c8f031c",
   "metadata": {},
   "source": [
    "h) Comparing misfit between Initial and Updated models\n",
    "- Now we have two files containing misfit, one for the initial model, and one for the updated model (M01)\n",
    "- Each line in the misfit file corresponds to the overall misfit for a single event\n",
    "- We can compare them by taking the average of all lines in the misfit file\n",
    "\n",
    "!!! Put the misfit equation here !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c4536-4267-4d42-9534-91af101865d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate misfit from each source\n",
    "misfit_init, misfit_m01 = [], []\n",
    "\n",
    "for src in sorted(glob(\"SOURCE_???\")):\n",
    "    m_init = np.loadtxt(os.path.join(src, \"MISFIT.txt\"))\n",
    "    m_01 = np.loadtxt(os.path.join(src, \"MISFIT_01.txt\"))\n",
    "    \n",
    "    misfit_init.append(m_init.sum() / len(m_init))\n",
    "    misfit_m01.append(m_01.sum() / len(m_01))\n",
    "    \n",
    "print(f\"MISFIT INITIAL MODEL = {sum(misfit_init) / len(misfit_init)}\")\n",
    "print(f\"MISFIT UPDATED MODEL = {sum(misfit_m01) / len(misfit_m01)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7225260-bed6-4141-92cd-798017472db8",
   "metadata": {},
   "source": [
    "## 7) Automating Inversions using SeisFlows\n",
    "\n",
    "- Of course, now that we have gone through the rigorous manual exercise of updating a velocity model, we can see how SeisFlows automates this procedure.\n",
    "- SeisFlows contains a built-in optimization library, which features gradient-descent, non-linear conjugate gradient (NLCG), and L-BFGS nonlinear optimization alogirthms\n",
    "- This library takes care of the scaling of the gradient, automating the line search and model update\n",
    "- Under the hood, SeisFlows essentialy performs what we just did, scaling the velocity model, re-running forward simulations and comparing misfit values\n",
    "- Misfit is either calculated with the default preprocessing module, or using Pyatoa, a software designed specifically for waveform misfit quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80930e4-dee7-464b-98c0-18d6618ceb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir /home/scoped/work/day_3/sfexample_2\n",
    "%cd /home/scoped/work/day_3/sfexample_2\n",
    "! seisflows examples setup 2 -r /home/scoped/specfem2d --event_id 1 --niter 1 --nsta 1 --with_mpi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f8626c-8654-42fb-b755-f8f2404f59fa",
   "metadata": {},
   "source": [
    "!!! analyze log message above here !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb4193b-bd74-4a3d-8dd5-f0caadd38af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! seisflows submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44fb922-5577-45e5-bbe1-438f6562b7f7",
   "metadata": {},
   "source": [
    "-------------\n",
    "\n",
    "The task will be finished when you see the log message:\n",
    "\n",
    "```bash\n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "                             COMPLETE ITERATION 01                              \n",
    "////////////////////////////////////////////////////////////////////////////////\n",
    "2022-09-16 21:25:38 (I) | setting current iteration to: 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f03f2-152c-48cc-9c58-88b78961e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"> output/ contains models, gradients, etc.\"\n",
    "! ls output\n",
    "! echo\n",
    "\n",
    "! echo \"> MODEL directories contain SPECFEM formatted model files\"\n",
    "! ls output/MODEL_INIT\n",
    "! echo\n",
    "\n",
    "! echo \"> GRADIENT directories contain regularized misfit kernels\"\n",
    "! ls output/GRADIENT_01\n",
    "! echo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea91f98-8b87-47c8-be18-08f3c7597ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models/gradients can be plotted directly from the command line\n",
    "! seisflows plot2d MODEL_01 vs --savefig m_01_vs.png\n",
    "Image(\"m_01_vs.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9989ea-c4d9-4200-b91d-2d5f034c0d3b",
   "metadata": {},
   "source": [
    "Under the hood, SeisFlows is simply running a number of individual SPECFEM working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200bbe58-e658-4d38-b8f4-bc4b9a2bfefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls scratch/solver/001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81a944-fde6-4328-8319-f37222d29122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
