{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347bc0f7-6dbe-454c-a95a-8469d8efe1c2",
   "metadata": {},
   "source": [
    "# SPECFEM Users Workshop -- Day 2 (Oct. 6, 2022)\n",
    "## Day 2b: Kernel Exercise\n",
    "\n",
    "\n",
    "- In this notebook we will have participants run their own adjoint simulation using Day 2a as a guide \n",
    "- We will use two homogeneous halfspace models for simplicity, building on the exercise from Day 1b  \n",
    "- Adjoint simulations are key for performing seismic imaging (Day 3) as their results guide iterative model updates during the inverse problem  \n",
    "- These instructions should be run from inside the Docker container, using Jupyter Lab (see *Docker Preamble* in Day 0). \n",
    "\n",
    "-----------\n",
    "\n",
    "**Relevant Links:** \n",
    "- Today's Notebook: https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/day_2b_kernels_exercise.ipynb\n",
    "- Completed Notebook https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_2b_kernels_exercise.ipynb\n",
    "- Day 0 Notebook (Container Testing): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_0_container_testing.ipynb\n",
    "- Day 1A Notebook (Intro SPECFEM): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_1a_intro_specfem2d.ipynb\n",
    "- Day 1B Notebook (Fwd. Simulations): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_1b_forward_simulations.ipynb\n",
    "- Day 2A Notebook (Adj. Simulations): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_2a_kernels.ipynb\n",
    "\n",
    "**Jupyter Quick Tips:**\n",
    "\n",
    "- **Run cells** one-by-one by hitting the $\\blacktriangleright$ button at the top, or by hitting `Shift + Enter`\n",
    "- **Run all cells** by hitting the $\\blacktriangleright\\blacktriangleright$ button at the top, or by running `Run -> Run All Cells`\n",
    "- **Currently running cells** that are still processing will have a `[*]` symbol next to them\n",
    "- **Finished cells** will have a `[1]` symbol next to them. The number inside the brackets represents what order this cell has been run in.\n",
    "- Commands that start with `!` are Bash commands (i.e., commands you would run from the terminal)\n",
    "- Commands that start with `%` are Jupyter Magic commands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0acd55c-e9b3-4448-a327-ea23b797d6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "-----------\n",
    "## 0) Setting Up a SPECFEM2D Working Directory\n",
    "\n",
    "- Let's set up a clean working directory to run SPECFEM2D  \n",
    "- We will be doing all our work in the directory `/home/scoped/work/day_2/exercise`, all the following cells assume that we are in this directory  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797fb508-998d-470a-8142-7e3e61a063c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages we might use in this notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from scipy.integrate import simps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c386f6-0c75-4d44-b532-a1455eefd1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make correct dir. and move there\n",
    "! mkdir -p /home/scoped/work/day_2/exercise\n",
    "%cd /home/scoped/work/day_2/exercise\n",
    "\n",
    "# Symlink the executables and copy the relevant DATA/ directory\n",
    "! ln -s /home/scoped/specfem2d/bin .\n",
    "! cp -r /home/scoped/specfem2d/EXAMPLES/Tape2007/DATA .\n",
    "! cp -f DATA/Par_file_Tape2007_onerec DATA/Par_file\n",
    "\n",
    "# Ensure that SPECFEM outputs required files for adjoint simulations\n",
    "! seisflows sempar -P DATA/Par_file save_model binary\n",
    "! seisflows sempar -P DATA/Par_file setup_with_binary_database 1\n",
    "\n",
    "! mkdir OUTPUT_FILES\n",
    "\n",
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6404755-a37c-40bf-aab5-377f46f57e9d",
   "metadata": {},
   "source": [
    "------------\n",
    "## 1) Target Model Forward Simulations\n",
    "\n",
    "- We'll use the homogeneous halfspace defined by default in the example as our target model\n",
    "- Remember that the model spans X = [0, 480000]m and Z = [0, 480000]m  \n",
    "- Also remember that there are 40 elements in X and Z, corresponding to element sizes of 12000m  \n",
    "- We need to set up the working directory before running our simulation\n",
    "\n",
    "### 1a) STATIONS\n",
    "- Using what you learned in Day 1, generate your own STATIONS file with an interesting configuration\n",
    "- Look at *'STATIONS_checker'* to get a refresher of how the STATIONS file should be configured\n",
    "- Try to use 100 stations  \n",
    "- Go crazy! Try to use Python (or your own language of choice) to design your array and create your STATIONS file\n",
    "- Potential configurations you could choose that might mimic a real world scenario:  \n",
    "    a) Cross shaped linear array  \n",
    "    b) Uniform, dense gridded array  \n",
    "    c) Spiral  \n",
    "    d) Concentric rings  \n",
    "    e) Dense linear array mimicing a DAS sensor  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c931b1f7-6aed-4d07-b3d8-a23c3cda3e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go for (c) Spiral\n",
    "theta = np.radians(np.linspace(0, 360*5, 100))  # 100 stations  \n",
    "c = 240  # scale factor for spread in stations\n",
    "shift = c * 1E3\n",
    "r = theta ** 2\n",
    "x = (c * r * np.cos(theta)) + shift\n",
    "z = (c * r * np.sin(theta)) + shift\n",
    "\n",
    "plt.scatter(x, z, c=\"r\", marker=\"v\")  \n",
    "plt.xlim([0, 480E3])\n",
    "plt.ylim([0, 480E3])\n",
    "\n",
    "plt.title(\"Spiral Station Configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ed370-bdc9-4e19-b0ea-ac1905c741ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the coordinates to STATIONS file\n",
    "with open(\"DATA/STATIONS\", \"w\") as f:\n",
    "    for i, (x_, z_) in enumerate(zip(x, z)):\n",
    "        f.write(f\"S{i:0>6} AA {x_:9.2f} {z_:9.2f} 0. 0.\\n\")\n",
    "\n",
    "! head DATA/STATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba99890-1233-463b-a579-693f48b0644c",
   "metadata": {},
   "source": [
    "### 1b) SOURCE\n",
    "- Let's set our SOURCE here\n",
    "- Use one of the available 'SOURCE_???' files as a template\n",
    "- Remember that SPECFEM2D is expecting a file called SOURCE  \n",
    "- Can you use an interesting moment tensor configuration?  \n",
    "- Can you place the SOURCE somewhere it would be interesting based on your station configuration?  \n",
    "- e.g., at the center of a spiral or rings, normal to a linear array or grid, at one end of a linear array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd0a5cc-d0a5-405c-83a4-e4a3aeb3c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's place the SOURCE at the center of the spiral, with explosive MT\n",
    "! cp -f DATA/SOURCE_001 DATA/SOURCE\n",
    "\n",
    "lines = open(\"DATA/SOURCE\", \"r\").readlines()\n",
    "for i, line in enumerate(lines):\n",
    "    if \"xs\" in line:\n",
    "        lines[i] = \"xs = 240000\\n\"\n",
    "    elif \"zs\" in line: \n",
    "        lines[i] = \"zs = 240000\\n\"\n",
    "    else:\n",
    "        for value in [\"Mxx\", \"Mzz\", \"Mxz\"]:\n",
    "            if value in line:\n",
    "                lines[i] = f\"{value} = 1.0\\n\"\n",
    "\n",
    "# Write the SOURCE file changes\n",
    "with open(\"DATA/SOURCE\", \"w\") as f:\n",
    "    f.writelines(lines)\n",
    "    \n",
    "# Check the file\n",
    "! head -5 DATA/SOURCE\n",
    "! echo\n",
    "! head -51 DATA/SOURCE | tail -n 3\n",
    "\n",
    "# Plot for reference\n",
    "plt.scatter(x, z, c=\"r\", marker=\"v\")  \n",
    "plt.scatter(240000, 240000, c=\"y\", marker=\"*\", edgecolor=\"k\", s=150)\n",
    "plt.xlim([0, 480E3])\n",
    "plt.ylim([0, 480E3])\n",
    "\n",
    "plt.title(\"Spiral Station Configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d32129-3855-4ece-b649-1690b3661c74",
   "metadata": {},
   "source": [
    "### 1c) Run the Mesher and Solver  \n",
    "\n",
    "1) Tell SPECFEM to use your STATIONS file, and not it's internal definition of stations\n",
    "2) Run your simulation in **parallel** using 4 cores\n",
    "    - *Remember* that you need to tell both SPECFEM and MPI that you are planning to run 4 processes  \n",
    "\n",
    "The remainder of the `Par_file` should already be set up appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f33370d-7095-4072-9937-74175e411fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! seisflows sempar -P DATA/Par_file use_existing_stations .true.\n",
    "! seisflows sempar -P DATA/Par_file nproc 4\n",
    "\n",
    "! mpirun -n 4 bin/xmeshfem2D > output_mesher.txt\n",
    "! mpirun -n 4 bin/xspecfem2D > output_solver.txt\n",
    "\n",
    "! tail output_solver.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6732e2f-3474-4439-b133-d568d023b977",
   "metadata": {},
   "source": [
    "### 1d) Save Results\n",
    "- Make sure you **save the seismograms** output by SPECFEM somewhere safe \n",
    "- Remember that our displacement seismograms are stored in the *OUTPUT_FILES/* directory with the extension '*.semd*'\n",
    "- Subsequent simulations will **overwrite** files in the DATA/ and OUTPUT_FILES/ directory  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859243d-3be1-40fc-afa6-fd11debac2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir target_synthetics\n",
    "! cp OUTPUT_FILES/*semd target_synthetics\n",
    "! ls target_synthetics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211041b7-0881-4958-adcb-9cf31f7d590e",
   "metadata": {},
   "source": [
    "------------\n",
    "## 2) Initial Model Forward Simulations\n",
    "\n",
    "- Now we want to edit the current model definition to create an initial or 'starting' model\n",
    "- The starting model will also be a homogeneous halfspace  \n",
    "- We'll use what we learned in the [Day 1B exercise](https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_1b_forward_simulations.ipynb) to change the model parameters\n",
    "\n",
    "### 2a) Edit Velocity Model\n",
    "- The velocity model is defined in the `Par_file`\n",
    "- Let's **decrease** the velocity values (Vp and Vs) of the starting model by 20\\%  \n",
    "- *Remember* from Day 1B that we can use SeisFlows to view and change the velocity model parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ef0a5b-bc38-4694-b874-218a87cc14b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at velocity model parameters\n",
    "! seisflows sempar -P DATA/Par_file velocity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce5d9bf-2fb5-4f3c-ac8c-12681f1b14e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = 5800.\n",
    "vs = 3500.\n",
    "vp_new = vp - vp * 0.2\n",
    "vs_new = vs - vs * 0.2\n",
    "\n",
    "print(f\"vp: {vp} -> {vp_new}\")\n",
    "print(f\"vs: {vs} -> {vs_new}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d8fc69-075f-426f-a0bb-d6f53433b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! seisflows sempar -P DATA/Par_file velocity_model \"1 1 2600.d0 3500.d0 2800.0d0 0 0 10.d0 10.d0 0 0 0 0 0 0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7896be89-0e76-4b90-a448-2afcd49ef2f4",
   "metadata": {},
   "source": [
    "### 2b) Set the `Par_file` for a Forward Simulation\n",
    "\n",
    "1) Tell SPECFEM to **save the forward wavefield** after the simulation  \n",
    "2) Tell SPECFEM to **output binary database files** (as opposed to ASCII files)  \n",
    "3) Tell SPECFEM to **save the model** in binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e52cb5-3a02-467e-a695-b424d6a082d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! seisflows sempar -P DATA/Par_file save_forward .true.\n",
    "! seisflows sempar -P DATA/Par_file setup_with_binary_database 1\n",
    "! seisflows sempar -P DATA/Par_file save_model binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1446249a-c2c8-4e18-b854-1fa00c80a6df",
   "metadata": {},
   "source": [
    "### 2c) Run the Mesher, Solver and Save Results  \n",
    "\n",
    "1) Run your simulation in **parallel** using 4 cores\n",
    "2) After your simulation, **save the seismograms** output by SPECFEM somewhere safe  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04cbf0-343f-4a3c-b78e-183aeae8dd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mpirun -n 4 bin/xmeshfem2D > output_mesher.txt\n",
    "! mpirun -n 4 bin/xspecfem2D > output_solver.txt\n",
    "\n",
    "! tail output_solver.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1336826d-a628-4e08-bae5-8bd7bc448f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir initial_synthetics\n",
    "! cp OUTPUT_FILES/*semd initial_synthetics\n",
    "! ls initial_synthetics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b925ff0a-3c24-4ac3-9344-a5eb868ddcc7",
   "metadata": {},
   "source": [
    "### 2d) Optional: Visualize Waveforms\n",
    "\n",
    "- To make sure the two models were different, we can check our waveforms against one another  \n",
    "- Use Python to plot matching seismograms against one another  \n",
    "- Alternatively, you can use RecSec to plot *both* sets of synthetics, you'll need the following flags \n",
    "    - `--pysep_path`: path to tell RecSec where your 'data' is  \n",
    "    - `--syn_path`: path to tell RecSec where your 'synthetics' are  \n",
    "    - `--cmtsolution`: path to your 'SOURCE' file  \n",
    "    - `--stations`: path to your 'STATIONS' file  \n",
    "    - `--components`: the components of your seismograms. These are listed in the filenames (e.g., AA.S000099.BXY.semd is component 'Y')  \n",
    "    - `--synsyn`: flag to tell RecSec that we are plotting two sets of synthetics (not actual data)  \n",
    "    - `--cartesian`: flag to tell RecSec that our domain is cartesian (not geographic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9bd90-4aad-4e15-b975-364b9cc92b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting with RecSec and a few additional (bonus!) parameters\n",
    "! recsec --pysep_path initial_synthetics --syn_path target_synthetics --cmtsolution 'DATA/SOURCE' --stations 'DATA/STATIONS' \\\n",
    "    --scale_by global_norm --amplitude_scale_factor 10 --components XY --synsyn --cartesian -L INFO -o\n",
    "\n",
    "Image(\"record_section.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa4b06e-7cb6-4d62-965f-d42842c9b703",
   "metadata": {},
   "source": [
    "---------------\n",
    "## 3) Quantify Misfit, Generate Adjoint Sources\n",
    "\n",
    "- You should now have **two sets of synthetics**, one generated by your initial model, another by your target model\n",
    "- We now want to generate adjoint sources for each pair of synthetics\n",
    "- Let's use a cross correlation traveltime misfit function\n",
    "- The cross correlation misfit is defined: $\\chi (\\mathbf{m}) = \\frac{1}{2} \\left[ T^{obs} - T(\\mathbf{m}) \\right] ^ 2$, \n",
    "- Where $T^{obs}$ is the observed traveltime, and $T(\\mathbf{m})$ is the\n",
    "predicted traveltime in Earth model $m$\n",
    "\n",
    "### 3a) Define your Misfit Function\n",
    "\n",
    ">__Adjoint Source Equation:__ $f^{\\dagger}(t) = - \\left[ T^{obs} - T(\\mathbf{m}) \\right] ~ \\frac{1}{N} ~\n",
    "    \\partial_t \\mathbf{s}(T - t, \\mathbf{m})$\n",
    "       \n",
    "Complete the function below using the following steps:\n",
    "\n",
    "1) Calculate the time shift $\\left[ T^{obs} - T(\\mathbf{m})\\right]$ using [ObsPy's cross correlation function](https://docs.obspy.org/master/packages/autogen/obspy.signal.cross_correlation.correlate.html) \n",
    "    - The correlate function returns an array of correlation values\n",
    "    - Use [xcorr_max](https://docs.obspy.org/master/packages/autogen/obspy.signal.cross_correlation.xcorr_max.html#obspy.signal.cross_correlation.xcorr_max) to find the time shift related to the peak cross correlation\n",
    "    - The time shift should be a **single value**\n",
    "2) Assume the normalization factor $N$ is 1 (incorrect but simplified for convenience)  \n",
    "3) Differentiate the synthetic waveform, $\\partial_t \\mathbf{s}(t, \\mathbf{m})$,  using [NumPy gradient](https://numpy.org/doc/stable/reference/generated/numpy.gradient.html)  \n",
    "4) Time reverse the differentiated synthetic waveform $\\partial_t \\mathbf{s}(T - t, \\mathbf{m})$  \n",
    "5) Return an adjoint source that combines parts 1 through 4 that follows the **Adjoint Source Equation** above. Remember the -1!\n",
    "\n",
    "\n",
    "---------\n",
    "Start with the following template and try to follow steps above:\n",
    "```python\n",
    "from numpy import gradient\n",
    "from obspy.signal.cross_correlation import correlate, xcorr_max\n",
    "\n",
    "\n",
    "def cc_traveltime_adjsrc(d, s):\n",
    "    \"\"\"\n",
    "    Define a cross-correlation traveltime adjoint source\n",
    "    \n",
    "    :type d: np.array\n",
    "    :param d: data array\n",
    "    :type s: np.array\n",
    "    :param s: synthetic array\n",
    "    :rtype adj_src: np.array\n",
    "    :return adj_src: adjoint source array\n",
    "    \"\"\"\n",
    "    # follow steps 1-5 here\n",
    "    # ...\n",
    "    return adj_src\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb60ce-a0e6-4da9-9fb5-08d66655af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import gradient\n",
    "from obspy.signal.cross_correlation import correlate, xcorr_max\n",
    "\n",
    "def cc_traveltime_adjsrc(d, s):\n",
    "    \"\"\"\n",
    "    Define a cross-correlation traveltime adjoint source\n",
    "    \n",
    "    :type d: np.array\n",
    "    :param d: data array\n",
    "    :type s: np.array\n",
    "    :param s: synthetic array\n",
    "    :rtype adj_src: np.array\n",
    "    :return adj_src: adjoint source array\n",
    "    \"\"\"\n",
    "    # Step 1: calculate time shift\n",
    "    cc = correlate(d, s, shift=100)\n",
    "    tshift, value = xcorr_max(cc)\n",
    "    \n",
    "    # Step 2: assume normalization factor\n",
    "    norm = 1\n",
    "    \n",
    "    # Step 3: differentiate synthetic\n",
    "    ds = gradient(s)\n",
    "    \n",
    "    # Step 4: time-reverse differentiated synthetic\n",
    "    ds = ds[::-1]\n",
    "    \n",
    "    # Step 5: Multiply by -1\n",
    "    minus_one = -1\n",
    "    \n",
    "    # Step 6: Define adj src\n",
    "    adj_src = -1 * tshift / norm * ds\n",
    "    \n",
    "    return adj_src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a33fc98-5102-4095-aba9-95bd05a7f78f",
   "metadata": {},
   "source": [
    "### 3b) Generate Adjoint Sources\n",
    "\n",
    "1) **Loop** through all available data and synthetic seismogram files, make sure filenames match!  \n",
    "1) **Load** in data and synthetic seismogram for a single station (use `numpy.loadtxt`; see Day 2A; Section 2C)\n",
    "2) **Apply** your adjoint source function from 3A to **output** an adjoint source array  \n",
    "3) **Save** the corresponding adjoint source in the `SEM/` directory (using `numpy.savetxt`; see Day 2A; Section 3A)\n",
    "    - *Remember* to format the adjoint source the same as the input synthetics\n",
    "    - *Remember* that adjoint sources must mimic the synthetic filename, but end with *.adj*\n",
    "    \n",
    "*Feel free to import Python modules required to file match and loop!*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138f433-d70b-49df-8450-697a17d6a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Make sure SEM directory exists\n",
    "! rm -r SEM/\n",
    "! mkdir SEM/\n",
    "\n",
    "# Step 1: Loop through data\n",
    "for path_initial in glob(\"initial_synthetics/*.semd\"):\n",
    "    # Making sure filenames match\n",
    "    fid = os.path.basename(path_initial)\n",
    "    path_target = f\"target_synthetics/{fid}\"\n",
    "    \n",
    "    # Step 2: Load in data using numpy loadtxt\n",
    "    t_init, d_init = np.loadtxt(path_initial).T\n",
    "    t_trgt, d_trgt = np.loadtxt(path_target).T\n",
    "    \n",
    "    # Step 3: Apply adjoint source function\n",
    "    d_adjsrc = cc_traveltime_adjsrc(d=d_init, s=d_trgt)\n",
    "    \n",
    "    # Step 4: Write adjoint sources\n",
    "    adj_src = np.vstack((t_init, d_adjsrc)).T\n",
    "    np.savetxt(f\"SEM/{fid.replace('.semd', '.adj')}\", adj_src)\n",
    "\n",
    "! ls SEM/\n",
    "! echo\n",
    "! head SEM/AA.S000000.BXY.adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c88da47-7d2d-47ae-9a20-e97e34f3c1c4",
   "metadata": {},
   "source": [
    "------------\n",
    "## 4) Run Adjoint Simulations\n",
    "\n",
    "- *Remember* to tell SPECFEM that this is an adjoint simulation (not a forward simulation)\n",
    "- *Remember* to tell SPECFEM to **output** kernel files in FORTRAN Binary format\n",
    "- Make sure that your adjoint sources are stored in the `SEM/` directory (Step 3)  \n",
    "- Make sure your DATABASE files are available in the *OUTPUT_FILES/* directory (Step 2)  \n",
    "- Remember you do **not** need to run the mesher, only the solver  \n",
    "- Check the output log file and kernel files to make sure you ran an adjoint simulation (not forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa727f-2973-4777-a0b5-e0340343f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! seisflows sempar -P DATA/Par_file simulation_type 3\n",
    "! seisflows sempar -P DATA/Par_file save_ASCII_kernels .false.\n",
    "\n",
    "! mpirun -n 4 bin/xspecfem2D > adjoint_solver.txt\n",
    "\n",
    "# Check that we've created the kernel files\n",
    "! tail adjoint_solver.txt\n",
    "! ls OUTPUT_FILES/*.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4b6172-d231-4ecf-b392-fcd3e1c6b977",
   "metadata": {},
   "source": [
    "## 5) Smooth Kernel\n",
    "- **Smooth** your Vp and Vs kernels by 10km in the horizontal direction and 10 km in the vertical\n",
    "- Make sure that SPECFEM can find the appropriate files (kernels, database and model files are all locatable in the same directory)  \n",
    "- Look at Day 2A Section 4 if you need help calling the smoothing executable  \n",
    "- Remember to run the smoother with 4 MPI processors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a6d185-d8c3-4549-8449-680bc4bc750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth the Vp and Vs kernels\n",
    "! cp DATA/*bin OUTPUT_FILES\n",
    "\n",
    "! mpirun -n 4 bin/xsmooth_sem 10000 10000 alpha_kernel OUTPUT_FILES/ OUTPUT_FILES/ .false.\n",
    "! mpirun -n 4 bin/xsmooth_sem 10000 10000 beta_kernel OUTPUT_FILES/ OUTPUT_FILES/ .false."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f009532-97f8-4143-9d27-21ef83cee1f1",
   "metadata": {},
   "source": [
    "-------------\n",
    "## 6) Visualize Results\n",
    "- Use SeisFlows (see Day 2a, Section 4) or NumPy + Matplotlib to visualize your kernel results  \n",
    "- Does your kernel make sense?\n",
    "- Can you plot the sources and stations on top of the kernel figure?\n",
    "- **NOTE:** If you use SeisFlows, you'll need to import the Model tool and change the names of the kernels from 'alpha' -> 'vp' and 'beta' -> 'vs'\n",
    "\n",
    "```python \n",
    "from seisflows.tools.specfem import Model\n",
    "# OR\n",
    "from seisflows.tools.specfem import read_fortran_binary\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37fb45-a1bf-4448-9db1-f809e66aff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually do this for convenience\n",
    "! mv OUTPUT_FILES/proc000000_alpha_kernel_smooth.bin OUTPUT_FILES/proc000000_vp_kernel.bin\n",
    "! mv OUTPUT_FILES/proc000001_alpha_kernel_smooth.bin OUTPUT_FILES/proc000001_vp_kernel.bin\n",
    "! mv OUTPUT_FILES/proc000002_alpha_kernel_smooth.bin OUTPUT_FILES/proc000002_vp_kernel.bin\n",
    "! mv OUTPUT_FILES/proc000003_alpha_kernel_smooth.bin OUTPUT_FILES/proc000003_vp_kernel.bin\n",
    "\n",
    "! mv OUTPUT_FILES/proc000000_beta_kernel_smooth.bin OUTPUT_FILES/proc000000_vs_kernel.bin\n",
    "! mv OUTPUT_FILES/proc000001_beta_kernel_smooth.bin OUTPUT_FILES/proc000001_vs_kernel.bin\n",
    "! mv OUTPUT_FILES/proc000002_beta_kernel_smooth.bin OUTPUT_FILES/proc000002_vs_kernel.bin\n",
    "! mv OUTPUT_FILES/proc000003_beta_kernel_smooth.bin OUTPUT_FILES/proc000003_vs_kernel.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def5150-09c7-409e-99f2-623c9186c05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seisflows.tools.specfem import Model\n",
    "\n",
    "m = Model(\"OUTPUT_FILES\", fmt=\".bin\")\n",
    "m.plot2d(\"vp\", show=False)\n",
    "plt.scatter(x, z, c=\"r\", marker=\"v\")  \n",
    "plt.scatter(240000, 240000, c=\"y\", marker=\"*\", edgecolor=\"k\", s=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
