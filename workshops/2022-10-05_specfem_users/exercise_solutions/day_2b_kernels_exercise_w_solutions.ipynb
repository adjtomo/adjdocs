{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347bc0f7-6dbe-454c-a95a-8469d8efe1c2",
   "metadata": {},
   "source": [
    "# SPECFEM Users Workshop -- Day 2 (Oct. 6, 2022)\n",
    "## Day 2b: Kernel Exercise\n",
    "\n",
    "\n",
    "- In this notebook we will have participants run their own adjoint simulation using Day 2a as a guide \n",
    "- We will use two homogeneous halfspace models for simplicity, building on the exercise from Day 1b  \n",
    "- Adjoint simulations are key for performing seismic imaging (Day 3) as their results guide iterative model updates during the inverse problem  \n",
    "- These instructions should be run from inside a Docker container, using Jupyter Lab (see instructions [here](https://github.com/adjtomo/adjdocs/blob/main/readmes/docker_image_install.md)).  \n",
    "-----------\n",
    "\n",
    "**Relevant Links:** \n",
    "- Today's Notebook: https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/day_2b_kernels_exercise.ipynb\n",
    "- Completed Notebook https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_2b_kernels_exercise.ipynb\n",
    "- Day 0 Notebook (Container Testing): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_0_container_testing.ipynb\n",
    "- Day 1A Notebook (Intro SPECFEM): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_1a_intro_specfem2d.ipynb\n",
    "- Day 1B Notebook (Fwd. Simulations): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_1b_forward_simulations.ipynb\n",
    "- Day 2A Notebook (Adj. Simulations): https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_2a_kernels.ipynb\n",
    "\n",
    "**Jupyter Quick Tips:**\n",
    "\n",
    "- **Run cells** one-by-one by hitting the $\\blacktriangleright$ button at the top, or by hitting `Shift + Enter`\n",
    "- **Run all cells** by hitting the $\\blacktriangleright\\blacktriangleright$ button at the top, or by running `Run -> Run All Cells`\n",
    "- **Currently running cells** that are still processing will have a `[*]` symbol next to them\n",
    "- **Finished cells** will have a `[1]` symbol next to them. The number inside the brackets represents what order this cell has been run in.\n",
    "- Commands that start with `!` are Bash commands (i.e., commands you would run from the terminal)\n",
    "- Commands that start with `%` are Jupyter Magic commands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0acd55c-e9b3-4448-a327-ea23b797d6a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "-----------\n",
    "## 0) Setting Up a SPECFEM2D Working Directory\n",
    "\n",
    "- Let's set up a clean working directory to run SPECFEM2D  \n",
    "- We will be doing all our work in the directory `/home/scoped/work/day_2/exercise`, all the following cells assume that we are in this directory  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797fb508-998d-470a-8142-7e3e61a063c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages we might use in this notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c386f6-0c75-4d44-b532-a1455eefd1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make correct dir. and move there\n",
    "! mkdir -p /home/scoped/work/day_2/exercise\n",
    "%cd /home/scoped/work/day_2/exercise\n",
    "\n",
    "# Symlink the executables and copy the relevant DATA/ directory\n",
    "! ln -s /home/scoped/specfem2d/bin .\n",
    "! cp -r /home/scoped/specfem2d/EXAMPLES/Tape2007/DATA .\n",
    "! cp -f DATA/Par_file_Tape2007_onerec DATA/Par_file\n",
    "\n",
    "# Ensure that SPECFEM outputs required files for adjoint simulations\n",
    "! seisflows sempar -P DATA/Par_file save_model binary\n",
    "! seisflows sempar -P DATA/Par_file setup_with_binary_database 1\n",
    "\n",
    "! mkdir OUTPUT_FILES\n",
    "\n",
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6404755-a37c-40bf-aab5-377f46f57e9d",
   "metadata": {},
   "source": [
    "------------\n",
    "## 1) Target Model Forward Simulations\n",
    "\n",
    "- We'll use the **homogeneous halfspace** defined by default in the example as our target model\n",
    "- Remember that the model spans X = [0, 480000]m and Z = [0, 480000]m  \n",
    "- Also remember that there are 40 elements in X and Z, corresponding to element sizes of 12000m  \n",
    "\n",
    "### 1a) STATIONS\n",
    "- Using what you learned in Day 1, generate your own STATIONS file with an interesting configuration\n",
    "- Look at *'STATIONS_checker'* to get a refresher of how the STATIONS file should be configured  \n",
    "- *Remember* that eventually SPECFEM will be looking for a file called *'DATA/STATIONS'*\n",
    "\n",
    "#### Choose your adventure:  \n",
    "- **Easier approach**: Use the first 25 stations in the *'STATIONS_checker'* file  \n",
    "- **Moderate approach**: Generate a horizontal or vertical line of 25 stations across your domain  \n",
    "- **Advanced approach**: Use up to 100 stations to design an array configuration of your choice  \n",
    "    - Potential configurations you could choose that might mimic a real world seismic array:  \n",
    "        a) Cross shaped linear array  \n",
    "        b) Uniform, dense gridded array  \n",
    "        c) Spiral  \n",
    "        d) Concentric rings  \n",
    "        e) Dense linear array mimicing a DAS sensor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ed370-bdc9-4e19-b0ea-ac1905c741ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go for (c) Spiral\n",
    "theta = np.radians(np.linspace(0, 360*5, 100))  # 100 stations  \n",
    "c = 240  # scale factor for spread in stations\n",
    "shift = c * 1E3  # shift spiral into required domain  \n",
    "r = theta ** 2\n",
    "x = (c * r * np.cos(theta)) + shift\n",
    "z = (c * r * np.sin(theta)) + shift\n",
    "\n",
    "plt.scatter(x, z, c=\"r\", marker=\"v\")  \n",
    "plt.xlim([0, 480E3])\n",
    "plt.ylim([0, 480E3])\n",
    "\n",
    "plt.title(\"Spiral Station Configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11028ffe-ad9f-4dea-8d08-38906d900f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out the coordinates to STATIONS file\n",
    "with open(\"DATA/STATIONS\", \"w\") as f:\n",
    "    for i, (x_, z_) in enumerate(zip(x, z)):\n",
    "        f.write(f\"S{i:0>6} AA {x_:9.2f} {z_:9.2f} 0. 0.\\n\")\n",
    "\n",
    "! head DATA/STATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba99890-1233-463b-a579-693f48b0644c",
   "metadata": {},
   "source": [
    "### 1b) SOURCE\n",
    "- Let's create a SOURCE for our simulation\n",
    "- *Remember* that SPECFEM2D is expecting a file called *'DATA/SOURCE'*  \n",
    "\n",
    "\n",
    "#### Choose your adventure:  \n",
    "- **Easier approach**: Use **one** of the available 25 *'SOURCE_???'* files located in the 'DATA' directory  \n",
    "- **Moderate approach**: Use one of the available *'SOURCE_???'* files as a template, but change it's location to the center of the domain  \n",
    "- **Advanced approach**: Can you think of an interesting moment tensor configuration for your source? Explosions are always fun! Can you place the SOURCE somewhere it would be interesting based on your station configuration? e.g.,  \n",
    "    - at the center of a spiral or concentric rings  \n",
    "    - normal to a linear array or grid  \n",
    "    - at one end of a linear array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd0a5cc-d0a5-405c-83a4-e4a3aeb3c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's place the SOURCE at the center of the spiral, with explosive MT\n",
    "! cp -f DATA/SOURCE_001 DATA/SOURCE\n",
    "\n",
    "lines = open(\"DATA/SOURCE\", \"r\").readlines()\n",
    "for i, line in enumerate(lines):\n",
    "    if \"xs\" in line:\n",
    "        lines[i] = \"xs = 240000\\n\"\n",
    "    elif \"zs\" in line: \n",
    "        lines[i] = \"zs = 240000\\n\"\n",
    "    else:\n",
    "        for value in [\"Mxx\", \"Mzz\", \"Mxz\"]:\n",
    "            if value in line:\n",
    "                lines[i] = f\"{value} = 1.0\\n\"\n",
    "\n",
    "# Write the SOURCE file changes\n",
    "with open(\"DATA/SOURCE\", \"w\") as f:\n",
    "    f.writelines(lines)\n",
    "    \n",
    "# Check the file\n",
    "! head -5 DATA/SOURCE\n",
    "! echo\n",
    "! head -51 DATA/SOURCE | tail -n 3\n",
    "\n",
    "# Plot for reference\n",
    "plt.scatter(x, z, c=\"r\", marker=\"v\")  \n",
    "plt.scatter(240000, 240000, c=\"y\", marker=\"*\", edgecolor=\"k\", s=150)\n",
    "plt.xlim([0, 480E3])\n",
    "plt.ylim([0, 480E3])\n",
    "\n",
    "plt.title(\"Spiral Station Configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d32129-3855-4ece-b649-1690b3661c74",
   "metadata": {},
   "source": [
    "### 1c) Run the Mesher and Solver  \n",
    "\n",
    "1) *Remember* to tell SPECFEM to use your STATIONS file, and not it's internal definition of stations (see e.g., Day 2a, Section 2b)\n",
    "2) Run your simulation in **parallel** using 4 cores  \n",
    "    - *Remember* that you need to tell both SPECFEM and MPI that you are planning to run 4 processes  \n",
    "\n",
    "The remainder of the `Par_file` should already be set up appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f33370d-7095-4072-9937-74175e411fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! seisflows sempar -P DATA/Par_file use_existing_stations .true.\n",
    "! seisflows sempar -P DATA/Par_file nproc 4\n",
    "\n",
    "! mpirun -n 4 bin/xmeshfem2D > output_mesher.txt\n",
    "! mpirun -n 4 bin/xspecfem2D > output_solver.txt\n",
    "\n",
    "! tail output_solver.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6732e2f-3474-4439-b133-d568d023b977",
   "metadata": {},
   "source": [
    "### 1d) Save Your Results\n",
    "- Make sure you **save the seismograms** output by SPECFEM somewhere safe  \n",
    "- *Remember* that subsequent simulations will **overwrite** files in the DATA/ and OUTPUT_FILES/ directory  \n",
    "- Remember that displacement seismograms are stored in the *OUTPUT_FILES/* directory with the extension '*.semd*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859243d-3be1-40fc-afa6-fd11debac2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir target_synthetics\n",
    "! mv OUTPUT_FILES/*semd target_synthetics\n",
    "! ls target_synthetics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211041b7-0881-4958-adcb-9cf31f7d590e",
   "metadata": {},
   "source": [
    "------------\n",
    "## 2) Initial Model Forward Simulations\n",
    "\n",
    "- Let's edit the current model definition to create a separate initial or 'starting' model\n",
    "- The starting model will also be a homogeneous halfspace, but with slightly different velocities \n",
    "- We'll use what we learned in the [Day 1B exercise](https://github.com/adjtomo/adjdocs/blob/main/workshops/2022-10-05_specfem_users/completed_notebooks/day_1b_forward_simulations.ipynb) to change the model parameters  \n",
    "\n",
    "### 2a) Edit Velocity Model\n",
    "- *Remember* that the velocity model is defined in the `Par_file`\n",
    "- Let's **decrease** the velocity values (Vp and Vs) of the starting model by 20\\%  \n",
    "- In other words $V_p \\rightarrow V_p - V_p \\times 0.2$\n",
    "- *Remember* from Day 1B that we can use SeisFlows to view and change the velocity model parameters, you can also use a text editor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d8fc69-075f-426f-a0bb-d6f53433b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at velocity model parameters\n",
    "! seisflows sempar -P DATA/Par_file velocity_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff9f67-5bf9-4513-a50d-4456dbcf9805",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp = 5800.\n",
    "vs = 3500.\n",
    "vp_new = vp - vp * 0.2\n",
    "vs_new = vs - vs * 0.2\n",
    "\n",
    "print(f\"vp: {vp} -> {vp_new}\")\n",
    "print(f\"vs: {vs} -> {vs_new}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c454a1d-86a4-4578-99df-9c7d51debcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "! seisflows sempar -P DATA/Par_file velocity_model \"1 1 2600.d0 3500.d0 2800.0d0 0 0 10.d0 10.d0 0 0 0 0 0 0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7896be89-0e76-4b90-a448-2afcd49ef2f4",
   "metadata": {},
   "source": [
    "### 2b) Set the `Par_file` for a new Forward Simulation\n",
    "\n",
    "1) Tell SPECFEM to **save the forward wavefield** after the simulation  \n",
    "2) Tell SPECFEM to **output binary database files** (as opposed to ASCII files)  \n",
    "3) Tell SPECFEM to **save the model** in binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e52cb5-3a02-467e-a695-b424d6a082d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! seisflows sempar -P DATA/Par_file save_forward .true.\n",
    "! seisflows sempar -P DATA/Par_file setup_with_binary_database 1\n",
    "! seisflows sempar -P DATA/Par_file save_model binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1446249a-c2c8-4e18-b854-1fa00c80a6df",
   "metadata": {},
   "source": [
    "### 2c) Run the Mesher, Solver and Save Results  \n",
    "\n",
    "1) Run your simulation in **parallel** using 4 cores\n",
    "2) After your simulation, **save the seismograms** output by SPECFEM somewhere safe  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04cbf0-343f-4a3c-b78e-183aeae8dd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mpirun -n 4 bin/xmeshfem2D > output_mesher.txt\n",
    "! mpirun -n 4 bin/xspecfem2D > output_solver.txt\n",
    "\n",
    "! tail output_solver.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2595543a-6ee9-4264-9ccc-b8752149bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir initial_synthetics\n",
    "! mv OUTPUT_FILES/*semd initial_synthetics\n",
    "! ls initial_synthetics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b925ff0a-3c24-4ac3-9344-a5eb868ddcc7",
   "metadata": {},
   "source": [
    "### 2d) Optional: Visualize Waveforms\n",
    "\n",
    "- To make sure the two models were different, we can check our waveforms against one another  \n",
    "- Use Python to plot matching seismograms against one another  \n",
    "- Alternatively, you can use RecSec to plot *both* sets of synthetics, you'll need the following flags \n",
    "    - `--pysep_path`: path to tell RecSec where your 'data' is  \n",
    "    - `--syn_path`: path to tell RecSec where your 'synthetics' are  \n",
    "    - `--cmtsolution`: path to your 'SOURCE' file  \n",
    "    - `--stations`: path to your 'STATIONS' file  \n",
    "    - `--components`: the components of your seismograms. These are listed in the filenames (e.g., AA.S000099.BXY.semd is component 'Y')  \n",
    "    - `--synsyn`: flag to tell RecSec that we are plotting two sets of synthetics (not actual data)  \n",
    "    - `--cartesian`: flag to tell RecSec that our domain is cartesian (not geographic) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9bd90-4aad-4e15-b975-364b9cc92b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting with RecSec and a few additional (bonus!) parameters\n",
    "! recsec --pysep_path initial_synthetics --syn_path target_synthetics --cmtsolution 'DATA/SOURCE' --stations 'DATA/STATIONS' \\\n",
    "    --scale_by global_norm --amplitude_scale_factor 10 --components XY --synsyn --cartesian -L INFO -o\n",
    "\n",
    "Image(\"record_section.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa4b06e-7cb6-4d62-965f-d42842c9b703",
   "metadata": {},
   "source": [
    "---------------\n",
    "## 3) Quantify Misfit, Generate Adjoint Sources\n",
    "\n",
    "- You should now have **two sets of synthetics**, one generated by your initial model, another by your target model\n",
    "- We now want to generate adjoint sources for each pair of synthetics\n",
    "\n",
    "#### Choose your adventure:  \n",
    "- **Easier/Moderate approach**: Define a waveform difference misfit function as in Day 2a, Section 3b  \n",
    "- **Advanced approach**: Head to Section 3B to try and define a cross-correlation traveltime misfit function    \n",
    "\n",
    "### 3a_1) Easier/Moderate Approach: Waveform Misfit\n",
    "\n",
    "- Waveform misfit adjoint source: $f^\\dagger (t) = s(t) - d(t)$  \n",
    "- You can use the following as a template for defining your waveform misfit function\n",
    "\n",
    "---------\n",
    "Start with the following template and try to follow steps above:\n",
    "```python\n",
    "from scipy.integrate import simps\n",
    "\n",
    "\n",
    "def waveform_misfit(d, s):\n",
    "    \"\"\"\n",
    "    Define a waveform misft adjoint source\n",
    "    \n",
    "    :type d: np.array\n",
    "    :param d: data array\n",
    "    :type s: np.array\n",
    "    :param s: synthetic array\n",
    "    :rtype adj_src: np.array\n",
    "    :return adj_src: adjoint source array\n",
    "    \"\"\"\n",
    "    # follow steps 1-5 here\n",
    "    # ...\n",
    "    return adj_src\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e60445-5b5c-4bd8-93d6-d7f9ce7ac811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import simps\n",
    "\n",
    "\n",
    "def waveform_misfit(d, s):\n",
    "    \"\"\"\n",
    "    Define a waveform misft adjoint source\n",
    "    \n",
    "    :type d: np.array\n",
    "    :param d: data array\n",
    "    :type s: np.array\n",
    "    :param s: synthetic array\n",
    "    :rtype adj_src: np.array\n",
    "    :return adj_src: adjoint source array\n",
    "    \"\"\"\n",
    "    adj_src = s - d\n",
    "\n",
    "    return adj_src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151cfecc-e6ac-424d-a7f1-57cdaa473fc1",
   "metadata": {},
   "source": [
    "--------------------\n",
    "### 3a_2) Advanced Approach: Define a Cross-Correlation Traveltime Misfit Function\n",
    "\n",
    "- Let's use a cross correlation traveltime misfit function to define our adjoint source  \n",
    "- The cross correlation misfit is defined: $\\chi (\\mathbf{m}) = \\frac{1}{2} \\left[ T^{obs} - T(\\mathbf{m}) \\right] ^ 2$,  \n",
    "- Where $T^{obs}$ is the observed traveltime, and $T(\\mathbf{m})$ is the\n",
    "predicted traveltime in Earth model $m$  \n",
    "- **Alternatively**, you can use the waveform difference objective function we say in Day 2 Section 3A  \n",
    "\n",
    ">__Adjoint Source Equation:__ $f^{\\dagger}(t) = - \\left[ T^{obs} - T(\\mathbf{m}) \\right] ~ \\frac{1}{N} ~\n",
    "    \\partial_t \\mathbf{s}(T - t, \\mathbf{m})$\n",
    "       \n",
    "Complete the function below using the following steps:\n",
    "\n",
    "1) Calculate the time shift $\\left[ T^{obs} - T(\\mathbf{m})\\right]$ using [ObsPy's cross correlation function](https://docs.obspy.org/master/packages/autogen/obspy.signal.cross_correlation.correlate.html) \n",
    "    - The correlate function returns an array of correlation values\n",
    "    - Use [xcorr_max](https://docs.obspy.org/master/packages/autogen/obspy.signal.cross_correlation.xcorr_max.html#obspy.signal.cross_correlation.xcorr_max) to find the time shift related to the peak cross correlation\n",
    "    - The time shift should be a **single value**\n",
    "2) Differentiate the synthetic waveform, $\\partial_t \\mathbf{s}(t, \\mathbf{m})$,  using [NumPy gradient](https://numpy.org/doc/stable/reference/generated/numpy.gradient.html)  \n",
    "3) Set the normalization factor $N$ as:  $N = \\int_0^T ~ \\mathbf{s}(t, \\mathbf{m}) ~ \\partial^2_t \\mathbf{s}(t, \\mathbf{m}) dt$  \n",
    "    - Where T is the total seismogram time\n",
    "    - Use [SciPy's Simpson's rule](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.integrate.simps.html) to integrate  \n",
    "4) Time reverse the differentiated synthetic waveform $\\partial_t \\mathbf{s}(T - t, \\mathbf{m})$  \n",
    "5) Return an adjoint source that combines parts 1 through 4 that follows the **Adjoint Source Equation** above. Remember the -1!\n",
    "\n",
    "\n",
    "---------\n",
    "Start with the following template and try to follow steps above:\n",
    "```python\n",
    "from numpy import gradient\n",
    "from scipy.integrate import simps\n",
    "from obspy.signal.cross_correlation import correlate, xcorr_max\n",
    "\n",
    "\n",
    "def cc_traveltime_adjsrc(d, s):\n",
    "    \"\"\"\n",
    "    Define a cross-correlation traveltime adjoint source\n",
    "    \n",
    "    :type d: np.array\n",
    "    :param d: data array\n",
    "    :type s: np.array\n",
    "    :param s: synthetic array\n",
    "    :rtype adj_src: np.array\n",
    "    :return adj_src: adjoint source array\n",
    "    \"\"\"\n",
    "    # follow steps 1-5 here\n",
    "    # ...\n",
    "    return adj_src\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338af557-2d63-4f21-9993-2102f9da8c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import gradient\n",
    "from scipy.integrate import simps\n",
    "from obspy.signal.cross_correlation import correlate, xcorr_max\n",
    "\n",
    "def cc_traveltime_adjsrc(d, s):\n",
    "    \"\"\"\n",
    "    Define a cross-correlation traveltime adjoint source\n",
    "    \n",
    "    :type d: np.array\n",
    "    :param d: data array\n",
    "    :type s: np.array\n",
    "    :param s: synthetic array\n",
    "    :rtype adj_src: np.array\n",
    "    :return adj_src: adjoint source array\n",
    "    \"\"\"\n",
    "    # Step 1: calculate time shift\n",
    "    cc = correlate(d, s, shift=100)\n",
    "    tshift, value = xcorr_max(cc)\n",
    "    \n",
    "    # Step 2: differentiate synthetic\n",
    "    ds = gradient(s)\n",
    "    \n",
    "    # Step 3: Set normalization factor\n",
    "    norm = simps(s * (ds **2))\n",
    "    \n",
    "    # Step 4: time-reverse differentiated synthetic\n",
    "    ds = ds[::-1]\n",
    "    \n",
    "    # Step 5: Multiply by -1\n",
    "    minus_one = -1\n",
    "    \n",
    "    # Step 6: Define adj src\n",
    "    adj_src = -1 * tshift / norm * ds\n",
    "    \n",
    "    return adj_src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a33fc98-5102-4095-aba9-95bd05a7f78f",
   "metadata": {},
   "source": [
    "### 3b) Generate Adjoint Sources\n",
    "\n",
    "1) **Loop** through all available data and synthetic seismogram files, make sure filenames match!  \n",
    "1) **Load** in data and synthetic seismogram for a single station (use `numpy.loadtxt`; see Day 2A; Section 2C)\n",
    "2) **Apply** your adjoint source function from 3A to **output** an adjoint source array  \n",
    "3) **Save** the corresponding adjoint source in the `SEM/` directory (using `numpy.savetxt`; see Day 2A; Section 3A)\n",
    "    - *Remember* to format the adjoint source the same as the input synthetics\n",
    "    - *Remember* that adjoint sources must mimic the synthetic filename, but end with *.adj*\n",
    "    \n",
    "*Feel free to import Python modules required to file match and loop!*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1138f433-d70b-49df-8450-697a17d6a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Make sure SEM directory exists\n",
    "! rm -r SEM/\n",
    "! mkdir SEM/\n",
    "\n",
    "# Step 1: Loop through data\n",
    "for path_initial in glob(\"initial_synthetics/*.semd\"):\n",
    "    # Making sure filenames match\n",
    "    fid = os.path.basename(path_initial)\n",
    "    path_target = f\"target_synthetics/{fid}\"\n",
    "    \n",
    "    # Step 2: Load in data using numpy loadtxt\n",
    "    t_init, d_init = np.loadtxt(path_initial).T\n",
    "    t_trgt, d_trgt = np.loadtxt(path_target).T\n",
    "    \n",
    "    # Step 3: Apply adjoint source function\n",
    "    d_adjsrc = cc_traveltime_adjsrc(d=d_init, s=d_trgt)\n",
    "    \n",
    "    # Step 4: Write adjoint sources\n",
    "    adj_src = np.vstack((t_init, d_adjsrc)).T\n",
    "    np.savetxt(f\"SEM/{fid.replace('.semd', '.adj')}\", adj_src)\n",
    "\n",
    "! ls SEM/\n",
    "! echo\n",
    "! head SEM/AA.S000000.BXY.adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f48b1-68dd-404d-ab9a-b088530cf940",
   "metadata": {},
   "source": [
    "## 3c) Optional: Plot an adjoint source\n",
    "\n",
    "- It's always useful to look at adjoint sources before running an adjoint simulation  \n",
    "- Plot **one** adjoint source next to its corresponding data and synthetic waveforms if you can  \n",
    "- We should be able to immediately tell if the adjoint source looks appropriate  \n",
    "- *Remember* that we plotted adjoint sources in Day 2a Section 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d61d228-7ed8-4899-b500-501b0c28e028",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_init, d_init = np.loadtxt(\"initial_synthetics/AA.S000000.BXY.semd\").T\n",
    "t_true, d_true = np.loadtxt(\"target_synthetics/AA.S000000.BXY.semd\").T\n",
    "t_adj, d_adj = np.loadtxt(\"SEM/AA.S000000.BXY.adj\").T\n",
    "\n",
    "# Plot both waveforms using Matplotlib\n",
    "plt.plot(t_init, d_init, c=\"r\", label=\"MODEL INIT; SYNTHETIC\")\n",
    "plt.plot(t_true, d_true, c=\"k\", label=\"MODEL TRUE; 'DATA'\")\n",
    "plt.plot(t_init, d_adj, c=\"g\", label=\"ADJOINT SOURCE\")\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Displacement [m]\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c88da47-7d2d-47ae-9a20-e97e34f3c1c4",
   "metadata": {},
   "source": [
    "------------\n",
    "## 4) Run Adjoint Simulations\n",
    "\n",
    "- *Remember* to tell SPECFEM that this is an adjoint simulation (not a forward simulation)\n",
    "- *Remember* to tell SPECFEM to **output** kernel files in FORTRAN Binary format\n",
    "- Make sure that your adjoint sources are stored in the `SEM/` directory (Step 3)  \n",
    "- Make sure your DATABASE files are available in the *OUTPUT_FILES/* directory (Step 2)  \n",
    "- Remember you do **not** need to run the mesher, only the solver  \n",
    "- Check the output log file and kernel files to make sure you ran an adjoint simulation (not forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa727f-2973-4777-a0b5-e0340343f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! seisflows sempar -P DATA/Par_file simulation_type 3\n",
    "! seisflows sempar -P DATA/Par_file save_ASCII_kernels .false.\n",
    "\n",
    "! mpirun -n 4 bin/xspecfem2D > adjoint_solver.txt\n",
    "\n",
    "# Check that we've created the kernel files\n",
    "! tail adjoint_solver.txt\n",
    "! ls OUTPUT_FILES/*.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4b6172-d231-4ecf-b392-fcd3e1c6b977",
   "metadata": {},
   "source": [
    "## 5) Smooth Kernel\n",
    "- **Smooth** your Vp and Vs kernels by 10km in the horizontal direction and 10 km in the vertical\n",
    "- Make sure that SPECFEM can find the appropriate files (kernels, database and model files are all locatable in the same directory)  \n",
    "- Look at Day 2A Section 4 if you need help calling the smoothing executable  \n",
    "- Remember to run the smoother with 4 MPI processors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a6d185-d8c3-4549-8449-680bc4bc750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth the Vp and Vs kernels\n",
    "! cp DATA/*bin OUTPUT_FILES\n",
    "\n",
    "! mpirun -n 4 bin/xsmooth_sem 10000 10000 alpha_kernel OUTPUT_FILES/ OUTPUT_FILES/ .false.\n",
    "! mpirun -n 4 bin/xsmooth_sem 10000 10000 beta_kernel OUTPUT_FILES/ OUTPUT_FILES/ .false."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f009532-97f8-4143-9d27-21ef83cee1f1",
   "metadata": {},
   "source": [
    "-------------\n",
    "## 6) Visualize Results\n",
    "- Use SeisFlows (see Day 2a, Section 4) or NumPy + Matplotlib to visualize your kernel results  \n",
    "- Does your kernel make sense?\n",
    "- Can you plot the sources and stations on top of the kernel figure?\n",
    "- **NOTE:** If you use SeisFlows, you'll need to import the Model tool and change the names of the kernels from 'alpha' -> 'vp' and 'beta' -> 'vs'\n",
    "\n",
    "```python \n",
    "from seisflows.tools.specfem import Model\n",
    "# OR\n",
    "from seisflows.tools.specfem import read_fortran_binary\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37fb45-a1bf-4448-9db1-f809e66aff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually do this for convenience\n",
    "! mkdir KERNEL \n",
    "\n",
    "! cp -r DATA/*bin KERNEL\n",
    "\n",
    "! mv OUTPUT_FILES/proc000000_alpha_kernel_smooth.bin KERNEL/proc000000_vp_kernel.bin\n",
    "! mv OUTPUT_FILES/proc000001_alpha_kernel_smooth.bin KERNEL/proc000001_vp_kernel.bin\n",
    "! mv OUTPUT_FILES/proc000002_alpha_kernel_smooth.bin KERNEL/proc000002_vp_kernel.bin\n",
    "! mv OUTPUT_FILES/proc000003_alpha_kernel_smooth.bin KERNEL/proc000003_vp_kernel.bin\n",
    "\n",
    "! mv OUTPUT_FILES/proc000000_beta_kernel_smooth.bin KERNEL/proc000000_vs_kernel.bin\n",
    "! mv OUTPUT_FILES/proc000001_beta_kernel_smooth.bin KERNEL/proc000001_vs_kernel.bin\n",
    "! mv OUTPUT_FILES/proc000002_beta_kernel_smooth.bin KERNEL/proc000002_vs_kernel.bin\n",
    "! mv OUTPUT_FILES/proc000003_beta_kernel_smooth.bin KERNEL/proc000003_vs_kernel.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af448b01-1068-464e-b06c-240459d66b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seisflows.tools.specfem import Model\n",
    "\n",
    "m = Model(\"KERNEL\", fmt=\".bin\")\n",
    "m.plot2d(\"vs_kernel\", show=False)\n",
    "plt.scatter(x, z, c=\"r\", marker=\"v\")  \n",
    "plt.scatter(240000, 240000, c=\"y\", marker=\"*\", edgecolor=\"k\", s=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
